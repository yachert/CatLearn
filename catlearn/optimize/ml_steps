import numpy as np
from catlearn.optimize.io import ase_to_catlearn, store_results_neb, \
                                 print_version, store_trajectory_neb, \
                                 print_info_neb, array_to_ase, print_cite_mlneb
from catlearn.optimize.constraints import create_mask, apply_mask
from ase.neb import NEB
from ase.neb import NEBTools
from ase.io import read, write
from ase.optimize import MDMin
from ase.parallel import parprint, world, parallel_function
from scipy.spatial import distance
import os
from catlearn.regression import GaussianProcess
from ase.calculators.calculator import Calculator, all_changes
from ase.atoms import Atoms
from catlearn import __version__


class MLNEB(object):

    def __init__(self, start, end, prev_calculations=None,
                 n_images=0.25, k=None, interpolation='linear', mic=False,
                 neb_method='improvedtangent', ase_calc=None, restart=True,
                 force_consistent=None):

        """ Nudged elastic band (NEB) setup.

        Parameters
        ----------
        start: Trajectory file (in ASE format) or Atoms object.
            Initial end-point of the NEB path or Atoms object.
        end: Trajectory file (in ASE format).
            Final end-point of the NEB path.
        n_images: int or float
            Number of images of the path (if not included a path before).
             The number of images include the 2 end-points of the NEB path.
        k: float or list
            Spring constant(s) in eV/Ang.
        interpolation: string or Atoms list or Trajectory
            Automatic interpolation can be done ('idpp' and 'linear' as
            implemented in ASE).
            See https://wiki.fysik.dtu.dk/ase/ase/neb.html.
            Manual: Trajectory file (in ASE format) or list of Atoms.
            Atoms trajectory or list of Atoms containing the images along the
            path.
        neb_method: string
            NEB method as implemented in ASE. ('aseneb', 'improvedtangent'
            or 'eb').
            See https://wiki.fysik.dtu.dk/ase/ase/neb.html.
        ase_calc: ASE calculator Object.
            ASE calculator as implemented in ASE.
            See https://wiki.fysik.dtu.dk/ase/ase/calculators/calculators.html
        prev_calculations: Atoms list or Trajectory file (in ASE format).
            (optional) The user can feed previously calculated data for the
            same hypersurface. The previous calculations must be fed as an
            Atoms list or Trajectory file.
        restart: boolean
            Only useful if you want to continue your ML-NEB in the same
            directory. The file "evaluated_structures.traj" from the
            previous run, must be located in the same run directory.
        force_consistent: boolean or None
            Use force-consistent energy calls (as opposed to the energy
            extrapolated to 0 K). By default (force_consistent=None) uses
            force-consistent energies if available in the calculator, but
            falls back to force_consistent=False if not.

        """

        path = None

        # Convert Atoms and list of Atoms to trajectory files.
        if isinstance(start, Atoms):
            write('initial.traj', start)
            start = 'initial.traj'
        if isinstance(end, Atoms):
            write('final.traj', end)
            end = 'final.traj'
        if interpolation != 'idpp' and interpolation != 'linear':
            path = interpolation
        if isinstance(path, list):
            write('initial_path.traj', path)
            path = 'initial_path.traj'
        if isinstance(prev_calculations, list):
            write('prev_calcs.traj', prev_calculations)
            prev_calculations = 'prev_calcs.traj'

        # Start end-point, final end-point and path (optional).
        self.start = start
        self.end = end
        self.n_images = n_images
        self.feval = 0 
        '''
        â€œfunction evaluationsâ€ æˆ– â€œforce/energy evaluationsâ€ çš„è®¡æ•°å™¨ã€‚åˆå§‹åŒ–ä¸º 0ï¼Œåç»­æ¯æ¬¡è°ƒç”¨çœŸå®è®¡ç®—ï¼ˆASE calculatorï¼‰å¾—åˆ°èƒ½é‡/åŠ›æ—¶åº”æŠŠå®ƒå¢åŠ ã€‚
        ç”¨é€”ï¼šç”¨äºç»Ÿè®¡å·²åšäº†å¤šå°‘æ¬¡æ˜‚è´µçš„çœŸå®è®¡ç®—ï¼Œå¸¸ç”¨äºä¸»åŠ¨å­¦ä¹ ã€æˆæœ¬æ§åˆ¶å’Œæ—¥å¿—è¾“å‡ºã€‚
        '''
        # General setup.
        self.fc = force_consistent    # ä½¿ç”¨ä¸åŠ›ä¸€è‡´çš„èƒ½é‡ï¼ˆenergy that is consistent with forcesï¼‰ï¼›
        self.iter = 0                 # è¿­ä»£è®¡æ•°å™¨ï¼Œè¡¨ç¤º ML-NEB ä¸»å¾ªç¯å·²æ‰§è¡Œå¤šå°‘æ¬¡ï¼ˆä¾‹å¦‚æ¯æ¬¡é€‰å–æ–° image åšçœŸå®è®¡ç®—å¹¶æ›´æ–° GP å°±å¢åŠ ä¸€æ¬¡ï¼‰ã€‚
        self.ase_calc = ase_calc      # æŠŠç”¨æˆ·ä¼ å…¥çš„ ASE è®¡ç®—å™¨å¯¹è±¡ï¼ˆå¦‚ GPAWã€VASP wrapperã€æˆ–å…¶å®ƒ Calculatorï¼‰ä¿å­˜åˆ°å®ä¾‹ã€‚åç»­æ‰§è¡ŒçœŸå®èƒ½é‡/åŠ›è®¡ç®—æ—¶ä¼šç”¨åˆ°è¿™ä¸ªå¯¹è±¡ï¼Œæˆ–åœ¨åˆ›å»º/æ¢å¤ images æ—¶åˆ†é…ç»™æ¯ä¸ª imageã€‚
        self.ase = True
        self.mic = mic
        self.version = 'ML-NEB ' + __version__
        print_version(self.version)


        # Reset.
        self.constraints = None
        self.interesting_point = None # æ¸…é™¤â€œæœ‰è¶£ç‚¹â€è®°å½•ï¼ˆä¾‹å¦‚ä¸Šä¸€æ¬¡é€‰å‡ºçš„é‡‡æ ·ç‚¹æˆ–è¿‡æ¸¡æ€çŒœæµ‹ï¼‰ï¼Œä¸ºæ–°çš„ä¸»åŠ¨å­¦ä¹ å¾ªç¯é‡ç½®ã€‚
        self.acq = None
        self.gp = None                # æ¸…é™¤/é‡Šæ”¾å…ˆå‰çš„ Gaussian Process æ¨¡å‹å®ä¾‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå‡†å¤‡é‡æ–°æ„å»ºæˆ–åˆå§‹åŒ– GPã€‚

        msg = 'Error: Initial structure for the NEB was not provided.'
        assert start is not None, msg
        msg = 'Error: Final structure for the NEB was not provided.'
        assert end is not None, msg
        msg = 'ASE calculator not provided (see "ase_calc" flag).'
        assert self.ase_calc, msg                          # ç¡®ä¿æä¾›äº† ASE è®¡ç®—å™¨å¯¹è±¡ï¼ˆase_calcï¼‰ï¼Œå› ä¸ºåç»­éœ€è¦ç”¨å®ƒåšçœŸå®èƒ½é‡/åŠ›è®¡ç®—ã€‚è‹¥æ²¡æœ‰æä¾›å°±ä¼šæ–­è¨€å¤±è´¥å¹¶æ˜¾ç¤ºæç¤ºä¿¡æ¯ã€‚

        is_endpoint = read(start, '-1:')                   # è¿™æ˜¯ä¸€ä¸ªlistï¼Œè¿”å›ä¸€ä¸ªåªæœ‰æœ€åä¸€å¸§çš„åˆ—è¡¨ï¼ˆlist of Atomsï¼‰
        fs_endpoint = read(end, '-1:')
        is_pos = is_endpoint[-1].get_positions().flatten() # is_endpoint[-1] å–å‡ºæœ€åä¸€ä¸ª Atoms å¯¹è±¡
        '''
        å–å‡ºè¯»åˆ°çš„æœ€åä¸€å¸§ Atomsï¼ˆis_endpoint[-1]ï¼‰ï¼Œè°ƒç”¨ .get_positions() å¾—åˆ°å½¢çŠ¶ä¸º (N_atoms, 3) çš„ä½ç½®æ•°ç»„ï¼ˆæ¯è¡Œ [x,y,z]ï¼‰ã€‚
        flatten() æŠŠäºŒç»´æ•°ç»„æ‘Šå¹³æˆä¸€ç»´ï¼ˆé•¿åº¦ä¸º 3 * N_atomsï¼‰ï¼Œæ–¹ä¾¿åç»­æŒ‰ä¸€ç»´å‘é‡åšæ¯”è¾ƒæˆ–è®¡ç®—èŒƒæ•°ï¼ˆä¾‹å¦‚è®¡ç®—ä¸¤ç«¯ç‚¹ä¹‹é—´çš„æ€»ä½ç§»æˆ–è·¯å¾„é•¿åº¦ï¼‰
        '''
        fs_pos = fs_endpoint[-1].get_positions().flatten() 

        # Check the magnetic moments of the initial and final states:
        '''
        get_initial_magnetic_moments()ï¼šè¿™æ˜¯ ASE Atoms å¯¹è±¡çš„æ–¹æ³•ï¼Œç”¨æ¥è¿”å›æ¯ä¸ªåŸå­åœ¨è¯¥ Atoms å¯¹è±¡ä¸Šåˆå§‹è®¾ç½®çš„ç£çŸ©ï¼ˆmagmomsï¼‰ã€‚ä¸æ˜¯è®¡ç®—å¾—åˆ°çš„ç£çŸ©ï¼Œè€Œæ˜¯ Atoms ä¸Šçš„ magmoms å±æ€§ï¼ˆå¸¸ç”¨æ¥å‘Šè¯‰è®¡ç®—å™¨åˆå§‹è‡ªæ—‹ï¼‰ã€‚
        ä¸ºä»€ä¹ˆä¿å­˜ï¼šåœ¨å¤„ç†å«ç£æ€§çš„ä½“ç³»ï¼ˆä¾‹å¦‚é“ã€ç£æ€§è¿‡æ¸¡é‡‘å±è¡¨é¢ã€å¸é™„ç‰©å¸¦ç£çŸ©ï¼‰æ—¶ï¼Œèµ·å§‹æ€å’Œç»ˆæ­¢æ€çš„ç£çŸ©åˆ†å¸ƒå¯èƒ½ä¸åŒã€‚ML-NEB éœ€è¦çŸ¥é“è¿™ç‚¹æ¥ç¡®ä¿ ML ç‰¹å¾ä¸åç»­è®¡ç®—ä½¿ç”¨ä¸€è‡´çš„è‡ªæ—‹/ç£æ€§è®¾ç½®ï¼ˆæˆ–è€…åœ¨é‡åˆ°ç£æ€§ç¿»è½¬æ—¶é‡‡å–ç‰¹æ®Šå¤„ç†ï¼‰ã€‚
        å®è·µä¸­ï¼Œè¿™å¯ä»¥ç”¨æ¥ï¼šæ£€æµ‹ is ä¸ fs æ˜¯å¦å…·æœ‰ä¸åŒçš„ç£çŸ©è®¾ç½®ï¼ˆè‹¥ä¸åŒï¼Œå¯èƒ½éœ€äººä¸ºæŒ‡å®šæˆ–å¤„ç†è‡ªæ—‹ç¿»è½¬çš„é—®é¢˜ï¼‰ã€‚
        '''
        self.magmom_is = is_endpoint[-1].get_initial_magnetic_moments()
        self.magmom_fs = fs_endpoint[-1].get_initial_magnetic_moments()

        # Convert atoms information into data to feed the ML process.
        '''
        æ³¨é‡Šå¤„æ ‡æ˜ï¼šå°† Atomsï¼ˆæˆ–è½¨è¿¹ï¼‰è½¬æ¢ä¸ºä¾› CatLearn/GP ä½¿ç”¨çš„æ•°æ®ç»“æ„ï¼ˆç‰¹å¾ã€ç›®æ ‡ã€æ¢¯åº¦ç­‰ï¼‰ã€‚
        ase_to_catlearnï¼ˆåœ¨ä»£ç ä¸­è°ƒç”¨ï¼‰é€šå¸¸ä¼šï¼š
        éå† Atomsï¼ˆæˆ–è½¨è¿¹æ–‡ä»¶é‡Œçš„æ¯ä¸€å¸§ï¼‰ï¼Œç”Ÿæˆ ML æ‰€éœ€çš„ç‰¹å¾å‘é‡/æè¿°ç¬¦ï¼ˆlist_trainï¼‰ï¼›
        ç”Ÿæˆç›®æ ‡å€¼ï¼ˆèƒ½é‡ list_targetsï¼‰ä¸æ¢¯åº¦/åŠ›ï¼ˆlist_gradientsï¼‰ï¼›
        è¿”å›é™„å¸¦ imagesï¼ˆåŸå­åºåˆ—/traj framesï¼‰ã€constraintsï¼ˆçº¦æŸä¿¡æ¯ï¼‰ä¸ num_atoms ç­‰ä¿¡æ¯çš„å­—å…¸ trjã€‚
        '''
                   
        # Include Restart mode and previous calculations.
        # Restart / prev_calculations é€»è¾‘ï¼ˆå†³å®šç”¨å“ªäº›å·²è¯„ä¼°ç»“æ„ä½œä¸ºè®­ç»ƒé›†ï¼‰
        if restart is not True:
            # å½“ ä¸è¦æ±‚é‡å¯ï¼ˆrestart é Trueï¼‰æ—¶ï¼šç›´æ¥æŠŠèµ·ç‚¹ä¸ç»ˆç‚¹åˆå¹¶ä¸º merged_trajectoryï¼Œè½¬æ¢ä¸º ML æ•°æ®å¹¶å†™å…¥æ–‡ä»¶ evaluated_structures.trajã€‚ä¹Ÿå°±æ˜¯è¯´ä»å¤´å¼€å§‹ï¼Œä¸è¯»å–æ—§çš„è®­ç»ƒæ•°æ®ï¼Œè€ŒæŠŠå½“å‰ç«¯ç‚¹ä½œä¸ºå·²è¯„ä¼°æ ·æœ¬
            merged_trajectory = is_endpoint + fs_endpoint 
            trj = ase_to_catlearn(merged_trajectory)
            write('./evaluated_structures.traj', is_endpoint + fs_endpoint)

        if restart is True or prev_calculations is not None:
            if prev_calculations is None:
                eval_file = 'evaluated_structures.traj'
            if prev_calculations is not None:
                eval_file = prev_calculations
            if os.path.exists(eval_file):
                eval_atoms = read(eval_file, ':')
                trj = ase_to_catlearn(eval_atoms)
            if not os.path.exists(eval_file):
                merged_trajectory = is_endpoint + fs_endpoint
                trj = ase_to_catlearn(merged_trajectory)
                write('./evaluated_structures.traj', is_endpoint + fs_endpoint)

        self.list_train, self.list_targets, self.list_gradients, trj_images, \
            self.constraints, self.num_atoms = [trj['list_train'],
                                                trj['list_targets'],
                                                trj['list_gradients'],
                                                trj['images'],
                                                trj['constraints'],
                                                trj['num_atoms']]
        '''
        trj æ˜¯ ase_to_catlearn(...) çš„è¿”å›å€¼ï¼ˆå­—å…¸ï¼‰ã€‚è¿™é‡ŒæŠŠå­—å…¸é‡Œçš„å…³é”®å­—æ®µæ‹†å‡ºæ¥å¹¶èµ‹ç»™å®ä¾‹å±æ€§ï¼š
        list_trainï¼šç”¨äºè®­ç»ƒ GP çš„ç‰¹å¾/è¾“å…¥ï¼ˆé€šå¸¸æ¯ä¸ª entry å¯¹åº”ä¸€ä¸ªç»“æ„ï¼‰
        list_targetsï¼šå¯¹åº”çš„èƒ½é‡ï¼ˆlabelï¼‰åˆ—è¡¨
        list_gradientsï¼šå¯¹åº”çš„åŠ›/æ¢¯åº¦ï¼ˆè‹¥ GP è®­ç»ƒåŒæ—¶ä½¿ç”¨åŠ›ä¿¡æ¯ï¼‰
        trj_imagesï¼šåŸå§‹å¸§åˆ—è¡¨ï¼ˆæˆ– Atoms åˆ—è¡¨ï¼‰
        constraintsï¼šè‹¥åŸå­ä¸Šå­˜åœ¨çº¦æŸï¼ˆfixed atoms ç­‰ï¼‰ï¼Œä¼šä½œä¸ºç»“æ„ä¿¡æ¯è¿”å›
        num_atomsï¼šæ¯å¸§çš„åŸå­æ•°ï¼ˆæˆ–åœ¨ç‰¹å¾è½¬æ¢æ—¶è®°å½•çš„å€¼ï¼‰
        '''


        
         
        self.ase_ini = read(start) # è¯»å– start ä½œä¸º ASE å¯¹è±¡ï¼Œè®¾ç½®åŸå­æ•°
        self.num_atoms = len(self.ase_ini)
        if len(self.constraints) < 0:
            self.constraints = None
        if self.constraints is not None:
            self.index_mask = create_mask(self.ase_ini, self.constraints) # è¯¥å‡½æ•°é€šå¸¸æ ¹æ® Atoms å’Œçº¦æŸä¿¡æ¯è¿”å›ä¸€ä¸ªå¸ƒå°”æˆ–æ•´å‹ç´¢å¼•æ©ç ï¼Œæ ‡è®°å“ªäº›åŸå­è¢«å›ºå®šã€å“ªäº›è‡ªç”±ï¼Œä»è€Œåœ¨è®­ç»ƒ/é¢„æµ‹æ—¶å¿½ç•¥å—çº¦æŸçš„è‡ªç”±åº¦ã€‚

        # Obtain the energy of the endpoints for scaling:
        self.energy_is = is_endpoint[-1].get_potential_energy(
                                                      force_consistent=self.fc)
        self.energy_fs = fs_endpoint[-1].get_potential_energy(
                                                      force_consistent=self.fc)
        '''
        get_potential_energy æ˜¯ ASE Atoms çš„æ¥å£ï¼Œä¼šæŠŠè¯·æ±‚è½¬å‘ç»™åˆ†é…ç»™è¯¥ Atoms çš„ Calculator æ¥å®é™…è®¡ç®—æˆ–è¯»å€¼ã€‚
        force_consistent=self.fc æ˜¯æŠŠâ€œå¸Œæœ›ä½¿ç”¨ä¸åŠ›ä¸€è‡´çš„èƒ½é‡â€è¿™ä¸€æ„å›¾ä»¥å…³é”®å­—å‚æ•°ä¼ ç»™ Calculatorï¼›æ˜¯å¦ç”Ÿæ•ˆã€å¦‚ä½•å®ç°ã€è¿”å›å“ªä¸ªå­—æ®µï¼Œéƒ½æ˜¯ç”±å…·ä½“ Calculator/wrapper å†³å®šçš„ â€”â€” å› æ­¤åœ¨ä»£ç ä¸­éœ€è¦åšæ£€æŸ¥æˆ–ä¼˜é›…å›é€€ã€‚
        ---
        ã€ä½œç”¨ã€‘ï¼šå–èµ·ç‚¹ï¼ˆinitialï¼‰å’Œç»ˆç‚¹ï¼ˆfinalï¼‰çš„èƒ½é‡å€¼å¹¶ä¿å­˜ã€‚get_potential_energy ä¼šè§¦å‘è®¡ç®—å™¨è¿”å›èƒ½é‡ï¼ˆå¦‚æœå·²ç»è®¡ç®—è¿‡å¯èƒ½ä»ç¼“å­˜è¯»ï¼‰ï¼Œforce_consistent=self.fc æ§åˆ¶æ˜¯å¦å–â€œä¸åŠ›ä¸€è‡´â€çš„èƒ½é‡ï¼ˆä¹‹å‰ä½ é—®è¿‡è¿™ä¸ªï¼‰ï¼›self.fc çš„å«ä¹‰ï¼šTrue å¼ºåˆ¶ç”¨åŠ›ä¸€è‡´èƒ½é‡ï¼ŒNone åˆ™åœ¨è®¡ç®—å™¨æ”¯æŒæ—¶ä½¿ç”¨ï¼Œå¦åˆ™é€€å›æ™®é€šèƒ½é‡ã€‚
        ã€ç›®çš„ã€‘ï¼šä¸‹é¢ä¼šç”¨ç«¯ç‚¹èƒ½é‡æ¥**å½’ä¸€åŒ–/ç¼©æ”¾ï¼ˆscalingï¼‰**è®­ç»ƒç›®æ ‡ï¼ˆtargetsï¼‰ï¼Œä¾¿äº ML æ¨¡å‹ç¨³å®šè®­ç»ƒæˆ–æŠŠä¸åŒèƒ½é‡å°ºåº¦æ ‡å‡†åŒ–ã€‚
        '''

        # Set scaling of the targets:
        self.max_targets = np.max([self.energy_is, self.energy_fs]) # ä½œç”¨ï¼šå–ä¸¤ä¸ªç«¯ç‚¹èƒ½é‡çš„æœ€å¤§å€¼ä½œä¸º max_targetsã€‚é€šå¸¸ç”¨äºæŠŠæ‰€æœ‰è®­ç»ƒèƒ½é‡é™¤ä»¥è¯¥å€¼æˆ–åšç›¸å¯¹ç¼©æ”¾ï¼ˆä»£ç ä¸­ä¼ ç»™ create_ml_neb çš„ scaling_targets å‚æ•°ï¼‰ã€‚
        '''
        ä½œç”¨ï¼šå–ä¸¤ä¸ªç«¯ç‚¹èƒ½é‡çš„æœ€å¤§å€¼ä½œä¸º max_targetsã€‚é€šå¸¸ç”¨äºæŠŠæ‰€æœ‰è®­ç»ƒèƒ½é‡é™¤ä»¥è¯¥å€¼æˆ–åšç›¸å¯¹ç¼©æ”¾ï¼ˆä»£ç ä¸­ä¼ ç»™ create_ml_neb çš„ scaling_targets å‚æ•°ï¼‰ã€‚
        ç†ç”±ï¼šML å›å½’å¯¹ç›®æ ‡å°ºåº¦æ•æ„Ÿï¼ŒæŠŠèƒ½é‡æŒ‰ç«¯ç‚¹å°ºåº¦å½’ä¸€åŒ–å¯ä»¥è®©è®­ç»ƒæ›´ç¨³å®šã€è¶…å‚æ•°æ›´æ˜“è®¾å®šï¼Œä¹Ÿä¾¿äºæŠŠä¸åŒä½“ç³»åšç»Ÿä¸€å¤„ç†ã€‚æ³¨æ„ï¼šè‹¥ç«¯ç‚¹èƒ½é‡ä¸ºè´Ÿï¼ˆå¸¸è§ï¼‰ï¼Œmax å¯èƒ½ä¹Ÿæ˜¯è´Ÿæ•° â€”â€” éœ€çœ‹ create_ml_neb å¦‚ä½•ä½¿ç”¨å®ƒï¼ˆå¯èƒ½ç”¨ç»å¯¹å€¼æˆ–å¹³ç§»ï¼‰ï¼Œè¿™ç‚¹è¦ç•™æ„ã€‚
        '''

                   
        # Settings for the NEB.
        self.neb_method = neb_method                  # neb_methodï¼šä¿å­˜ä½ é€‰æ‹©çš„ NEB ç®—æ³•ï¼ˆå¦‚ 'improvedtangent'ï¼‰ã€‚
        self.spring = k                               # å¼¹ç°§å¸¸æ•°ï¼ˆkï¼‰ï¼Œç”¨äº NEB ä¸­ç›¸é‚»å›¾ç‰‡é—´å¼¹ç°§åŠ›çš„æ ‡é‡ï¼›æ­¤å¤„å…ˆä¿å­˜ç”¨æˆ·è¾“å…¥ï¼ˆå¯èƒ½ä¸º Noneï¼Œæ¥ä¸‹æ¥ä¼šè‡ªåŠ¨è®¾ç½®é»˜è®¤å€¼ï¼‰ã€‚
        self.initial_endpoint = is_endpoint[-1]       # initial_endpoint/final_endpointï¼šæŠŠ Atoms ç«¯ç‚¹å¯¹è±¡ä¿å­˜åˆ°å®ä¾‹ä¸­ï¼Œåç»­ç”¨äºæ’å€¼ä¸åˆ›å»º imagesã€‚
        self.final_endpoint = fs_endpoint[-1]

        # A) Create images using interpolation if user do not feed a path:
        if path is None:
            self.d_start_end = np.abs(distance.euclidean(is_pos, fs_pos)) # is_pos å’Œ fs_pos æ˜¯ä¹‹å‰å±•å¹³çš„ä¸€ç»´åæ ‡å‘é‡ï¼ˆé•¿åº¦ = 3 Ã— N_atomsï¼‰ã€‚distance.euclidean è®¡ç®—å®ƒä»¬çš„æ¬§æ°è·ç¦»ï¼Œè¿”å›å•ä¸ªæ ‡é‡ï¼Œä»£è¡¨â€œç«¯ç‚¹åæ ‡å‘é‡åœ¨é«˜ç»´ 3N ç©ºé—´çš„æ¬§æ°è·ç¦»â€â€”â€”è¿™å¸¸è¢«å½“ä½œè·¯å¾„é•¿åº¦çš„è¿‘ä¼¼ã€‚
            '''
            æ³¨æ„ï¼šè¿™ä¸ªâ€œè·¯å¾„é•¿åº¦â€æ˜¯åŸºäºæ‰€æœ‰åŸå­åæ ‡çš„ä¸€ç»´èŒƒæ•°ï¼Œä¸æ˜¯è´¨å¿ƒé—´è·æˆ–æœ€å¤§åŸå­ä½ç§»ï¼›åœ¨åŸå­æ•°å¾ˆå¤šæ—¶ï¼Œè¿™ä¸ªæ•°ä¼šæ¯”è¾ƒå¤§ã€‚è‹¥ä½“ç³»ä¸º PBCï¼Œéœ€è¦å…ˆç”¨ MICï¼ˆæœ€å°é•œåƒçº¦å®šï¼‰è°ƒæ•´åæ ‡ï¼Œå¦åˆ™è·ç¦»å¯èƒ½è¢«ç›’å­è¾¹ç•Œâ€œæ‹‰å¤§â€
            '''
          
            if isinstance(self.n_images, float):
                self.n_images = int(self.d_start_end/self.n_images) # å½“ n_images åŸæœ¬è¢«ç”¨ä½œâ€œé—´è·ï¼ˆÃ…ï¼‰â€çš„æµ®ç‚¹æ•°æ—¶ï¼Œä»£ç æŠŠå®é™…æ‰€éœ€é•œåƒæ•°è®¡ç®—ä¸ºxxxx
                if self.n_images <= 3:
                    self.n_images = 3
            if self.spring is None: # è‡ªåŠ¨è®¾ç½®å¼¹ç°§å¸¸æ•°ï¼ˆå¦‚æœç”¨æˆ·æœªç»™ï¼‰
                '''             
                è‹¥ç”¨æˆ·æœªæ˜¾å¼ç»™ kï¼ˆå¼¹ç°§å¸¸æ•°ï¼‰ï¼Œä»£ç ä½¿ç”¨è¿™ä¸ªç»éªŒå…¬å¼æ¥ç»™ä¸€ä¸ªé»˜è®¤å€¼ï¼šsqrt((n_images - 1) / d_start_end)ã€‚
                è§£é‡Šï¼šå¼¹ç°§å¸¸æ•°çš„å•ä½ä¸å®šä¹‰ä¾èµ–å®ç°ï¼Œè¿™ä¸ªå…¬å¼è¯•å›¾è®©â€œæ€»å¼¹ç°§åˆšåº¦â€éšæ®µæ•°å’Œè·¯å¾„é•¿åº¦è°ƒæ•´ï¼Œä»¥ä¾¿å¼¹ç°§åŠ›åœ¨ä¸åŒå›¾åƒæ•°æˆ–ä¸åŒè·¯å¾„é•¿åº¦ä¸‹ä¿æŒæŸç§å°ºåº¦ã€‚
                æ³¨æ„ï¼šè¯¥å…¬å¼å¯¹ d_start_end éå¸¸ä¾èµ–ï¼Œè‹¥ d_start_end æ¥è¿‘ 0 å°†å¯¼è‡´é™¤ä»¥ 0 æˆ–æ•°å€¼ä¸ç¨³å®šï¼ˆéœ€é˜²æŠ¤ï¼‰ã€‚
                ç‰©ç†ä¸Šå¼¹ç°§å¸¸æ•° k å•ä½ï¼ˆèƒ½é‡/è·ç¦»Â²ï¼‰ä¸è¿™é‡Œç”¨çš„è¡¨è¾¾å¯èƒ½ä»…ä¸ºå¯å‘å¼ï¼Œå®é™…éœ€è¦ç”¨ç»éªŒæˆ–è°ƒå‚å¾—åˆ°è¾ƒå¥½æ”¶æ•›æ€§
                '''
                self.spring = np.sqrt((self.n_images-1) / self.d_start_end)
              
            # è°ƒç”¨ create_ml_neb ç”Ÿæˆ imagesï¼ˆåŒ…å« ML ç›¸å…³å‚æ•°ï¼‰ï¼Œè¿”å›çš„ self.images å¾ˆå¯èƒ½æ˜¯ list[Atoms]
            # create_ml_nebï¼šè¿™æ˜¯ CatLearn çš„å‡½æ•°ï¼Œç”¨æ¥åˆ›å»ºä¸€ç³»åˆ— Atoms images ä½œä¸º NEB çš„åˆå§‹è·¯å¾„
            self.images = create_ml_neb(is_endpoint=self.initial_endpoint, # è¿™é‡Œ create_ml_neb çš„å‚æ•°åæ°å¥½å« is_endpointï¼Œä½†é‚£åªæ˜¯å‡½æ•°çš„å½¢å‚åå­—ã€‚ä½ æŠŠ self.initial_endpointï¼ˆä¸€ä¸ª Atomsï¼‰ä¼ è¿›å»ï¼Œå‡½æ•°å†…éƒ¨ä¼šæŠŠè¿™ä¸ª Atoms ç”¨ä½œèµ·ç‚¹ã€‚ å‚æ•°åçš„é‡å¤å¹¶ä¸å†²çªï¼šè°ƒç”¨æ—¶ is_endpoint= å·¦è¾¹æ˜¯å½¢å‚åï¼Œå³è¾¹æ˜¯ä½ ä¼ è¿›å»çš„å€¼ï¼ˆè¿™é‡Œæ˜¯ self.initial_endpointï¼‰ã€‚è¿™åœ¨ Python é‡Œéå¸¸å¸¸è§ã€‚
                                        fs_endpoint=self.final_endpoint,
                                        images_interpolation=None,         # æŒ‡ç¤ºä½¿ç”¨å†…éƒ¨é»˜è®¤æ’å€¼ï¼ˆä¸‹ä¸€æ­¥ä¼šç”¨ ASE çš„ NEB.interpolateï¼‰
                                        n_images=self.n_images,            # å‰é¢å¾—åˆ°çš„é•œåƒæ•°ï¼ˆåŒ…å«ç«¯ç‚¹è¿˜æ˜¯ä»…ä¸­é—´ï¼Ÿä¾å®ç°è€Œå®šï¼›é€šå¸¸æ˜¯åŒ…å«ç«¯ç‚¹ï¼‰
                                        constraints=self.constraints,      # è‹¥æœ‰å›ºå®šåŸå­ï¼Œéœ€ä¼ å…¥ä»¥ä¿è¯æ’å€¼ä¸æ”¹å˜å—é™åæ ‡ã€‚
                                        index_constraints=self.index_mask, 
                                        scaling_targets=self.max_targets,  # æŠŠç«¯ç‚¹èƒ½é‡å°ºåº¦ä¼ è¿›å»ï¼Œå¯èƒ½ç”¨äºå¯¹èƒ½é‡ç›®æ ‡åšå½’ä¸€åŒ–æˆ–å°†èƒ½é‡å¹³ç§»åˆ°æ›´åˆé€‚çš„è®­ç»ƒèŒƒå›´ã€‚
                                        iteration=self.iter,               # iteration=self.iterï¼šæŠŠå½“å‰è¿­ä»£æ•°ä¼ ç»™åˆ›å»ºå‡½æ•°ï¼ˆå¯èƒ½ç”¨äºå‘½åæˆ–è°ƒè¯•ä¿¡æ¯ï¼‰
                                        )

            neb_interpolation = NEB(self.images, k=self.spring) # æŠŠç”Ÿæˆçš„ self.images äº¤ç»™ ASE çš„ NEB å¯¹è±¡ï¼ˆä¸´æ—¶ç”¨äºåšæ’å€¼ï¼‰ï¼Œä¼ å…¥ k=self.springï¼ˆå¼¹ç°§å¸¸æ•°ï¼‰ã€‚
            neb_interpolation.interpolate(method=interpolation, mic=self.mic) # è°ƒç”¨æ’å€¼ï¼Œmethod å¯ä¸º 'linear' æˆ– 'idpp'ï¼›mic=self.mic è¡¨ç¤ºåœ¨æ’å€¼æ—¶æ˜¯å¦å¯ç”¨æœ€å°é•œåƒçº¦å®šï¼ˆPBC æƒ…å½¢ä¸‹æŒ‰æœ€è¿‘é•œåƒæ’å€¼ï¼‰
            '''
            æœ€ç»ˆç»“æœä¼šæŠŠ self.imagesï¼ˆæˆ– neb_interpolation å†…éƒ¨çš„ imagesï¼‰è°ƒæ•´ä¸ºæ’å€¼åçš„ç»“æ„ï¼Œä½œä¸ºåç»­ ML-NEB è¿­ä»£çš„åˆå§‹è·¯å¾„ã€‚
            '''

        # B) If the user sets a path:
        if path is not None:
            images_path = read(path, ':') # è¯»å–è¯¥è½¨è¿¹æ–‡ä»¶çš„æ‰€æœ‰å¸§ï¼Œimages_path å°†æ˜¯ list[Atoms]ï¼ˆè½¨è¿¹çš„æ¯ä¸€å¸§ï¼‰
            # è½¨è¿¹çš„â€œå¸§â€ï¼ASE çš„ Atomsï¼›åœ¨ NEB ä¸Šä¸‹æ–‡ä¸­è¿™äº› Atoms å°±è¢«ç§°ä¸ºâ€œimagesâ€

            if not np.array_equal(images_path[0].get_positions().flatten(),
                                  is_pos):
                images_path.insert(0, self.initial_endpoint)
            if not np.array_equal(images_path[-1].get_positions().flatten(),
                                  fs_pos):
                images_path.append(self.final_endpoint)
            '''
            ç¡®ä¿ images_path çš„é¦–å°¾ç¡®å®æ˜¯ä½ ä¼ å…¥çš„ start / endã€‚
            np.array_equal(...) æ¯”è¾ƒé¦–å¸§çš„ä½ç½®å‘é‡ä¸ is_posï¼ˆä¹‹å‰ä» start å¾—åˆ°çš„æ‰å¹³å‘é‡ï¼‰ï¼›å¦‚æœä¸ç›¸ç­‰ï¼Œå°±æŠŠ initial_endpoint æ’å…¥åˆ°åˆ—è¡¨å¼€å¤´ã€‚
            åŒç†ç¡®ä¿æœ€åä¸€å¸§ç­‰äº final_endpointï¼Œå¦‚æœæ²¡æœ‰åˆ™ appendã€‚
            '''

            self.n_images = len(images_path)
            self.images = create_ml_neb(is_endpoint=self.initial_endpoint,
                                        fs_endpoint=self.final_endpoint,
                                        images_interpolation=images_path,
                                        n_images=self.n_images,
                                        constraints=self.constraints,
                                        index_constraints=self.index_mask,
                                        scaling_targets=self.max_targets,
                                        iteration=self.iter,
                                        )
            self.d_start_end = np.abs(distance.euclidean(is_pos, fs_pos))

        # Save files with all the paths that have been predicted:
        '''
        æ„æ€ï¼šæŠŠå½“å‰ self.imagesï¼ˆlist of Atomsï¼‰å†™åˆ° all_predicted_paths.traj æ–‡ä»¶ï¼Œä»¥ä¾¿åç»­æŸ¥çœ‹ã€é‡å¯æˆ–è°ƒè¯•ã€‚
        æ³¨æ„ï¼šå›ºå®šæ–‡ä»¶åä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼Œå»ºè®®åœ¨å¹¶è¡Œæˆ–å¤šæ¬¡è¿è¡Œæ—¶ä½¿ç”¨å”¯ä¸€æ–‡ä»¶åæˆ–è®©ç”¨æˆ·ä¼ å…¥æ–‡ä»¶åå‚æ•°ã€‚
        '''
        write('all_predicted_paths.traj', self.images)
        
        self.uncertainty_path = np.zeros(len(self.images)) # ä¸ºæ¯å¼  image åˆå§‹åŒ–ä¸€ä¸ªä¸ç¡®å®šæ€§æ•°ç»„ uncertainty_pathï¼Œé•¿åº¦ç­‰äº images æ•°é‡ï¼Œåˆå§‹å…¨ 0ã€‚åç»­ GP ä¼šå¡«å…¥æ¯å¼  image çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œç”¨äºå†³ç­–è¦åœ¨å“ªå¼  image ä¸ŠåšçœŸå®è®¡ç®—ï¼ˆactive learningï¼‰ã€‚

        # Guess spring constant if spring was not set by the user: å¼¹ç°§å¸¸æ•°äºŒæ¬¡æ£€æŸ¥ï¼ˆå¦‚æœä¹‹å‰æ²¡è®¾ï¼‰
        if self.spring is None:
            self.spring = np.sqrt(self.n_images-1) / self.d_start_end

        # Get initial path distance:
        self.path_distance = self.d_start_end.copy() # æŠŠåˆå§‹è·¯å¾„é•¿åº¦ d_start_end å¤åˆ¶åˆ° self.path_distanceï¼Œä½œä¸ºè·¯å¾„é•¿åº¦çš„è®°å½•

        # Get forces for the previous steps è®¡ç®—ä¹‹å‰å·²è¯„ä¼°ç»“æ„çš„ forces çš„ fmaxï¼ˆæœ€å¤§åŠ›ï¼‰
        '''
        æ„æ€ï¼šéå† self.list_gradientsï¼ˆä¹‹å‰é€šè¿‡ ase_to_catlearn å¾—åˆ°çš„æ¢¯åº¦/åŠ›åˆ—è¡¨ï¼‰ï¼Œè®¡ç®—æ¯ä¸ªæ¢¯åº¦æ¡ç›®çš„ fmaxï¼ˆé€šå¸¸æ˜¯æ¯ç»“æ„çš„æœ€å¤§åŸå­åŠ›å¤§å°ï¼‰ï¼Œå¹¶æŠŠè¿™äº› max_abs_forces å­˜å…¥ self.list_max_abs_forcesã€‚
        å˜é‡/å‡½æ•°è¯´æ˜ï¼š
        self.list_gradientsï¼šåº”è¯¥æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€imageçš„åŠ›ï¼ˆå¯èƒ½æ˜¯ shape (N_atoms, 3) æˆ–å·²æ‰å¹³åŒ–çš„å‘é‡ï¼‰ã€‚
        get_fmax(...)ï¼šå¸¸è§çš„è¾…åŠ©å‡½æ•°ï¼Œæ¥æ”¶åŠ›æ•°ç»„å¹¶è¿”å›æ¯å¸§çš„ fmaxï¼ˆå¯èƒ½è¿”å›æ ‡é‡æˆ–æ•°ç»„ï¼Œå–å†³äºå®ç°ï¼‰ã€‚
        np.max(np.abs(...))ï¼šå¯¹ get_fmax çš„è¿”å›å–ç»å¯¹å€¼å¹¶å†å–æœ€å¤§ï¼Œç¡®ä¿å¾—åˆ°æ­£æ•°æ ‡é‡ã€‚
        æ³¨æ„/æ½œåœ¨é—®é¢˜ï¼š
        ä»£ç æŠŠ get_fmax(np.array([i])) çš„ç»“æœèµ‹ç»™ self.list_fmaxï¼ˆå®ä¾‹å±æ€§ï¼‰â€”â€”è¿™ä¼šè¢«å¾ªç¯è¦†ç›–ï¼ˆåªä¿ç•™æœ€åä¸€ä¸ªå€¼ï¼‰ã€‚å¦‚æœ list_fmax æœŸæœ›ä¿å­˜æ‰€æœ‰ fmaxï¼Œé‚£è¿™é‡Œåº”è¯¥ç”¨å±€éƒ¨å˜é‡å¹¶ appendï¼›ä½†å½“å‰é€»è¾‘åˆæŠŠ max_abs_forces append åˆ° list_max_abs_forcesï¼Œæ„å‘³ç€ self.list_fmax å¯èƒ½åªåšä¸´æ—¶å˜é‡è€Œè¯¯ç”¨äº†å®ä¾‹å±æ€§åã€‚
        '''
        self.list_max_abs_forces = []
        for i in self.list_gradients: # self.list_gradientsï¼ˆæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ª image çš„æ¢¯åº¦/åŠ›æ•°ç»„ï¼‰
                self.list_fmax = get_fmax(np.array([i]))
                self.max_abs_forces = np.max(np.abs(self.list_fmax))
                self.list_max_abs_forces.append(self.max_abs_forces)

        print_info_neb(self)
                   
    # ==================================================
    def run(self, fmax=0.05, unc_convergence=0.050, steps=500,
            trajectory='ML_NEB_catlearn.traj', acquisition='acq_5',
            dt=0.025, ml_steps=750, max_step=0.25, sequential=False,
            full_output=False):

        """Executing run will start the NEB optimization process.

        Parameters
        ----------
        fmax : float
            Convergence criteria (in eV/Angs). 
            çœŸå®è®¡ç®—/ä¼˜åŒ–çš„åŠ›æ”¶æ•›é˜ˆå€¼ï¼Œå•ä½ eV/Ã…ï¼ˆNEB/optimizer ç”¨ï¼‰ã€‚
        unc_convergence: float
            Maximum uncertainty for convergence (in eV). 
            ç”¨äºåˆ¤å®šæ•´ä½“ä¸ç¡®å®šæ€§æ”¶æ•›çš„é˜ˆå€¼ï¼ˆeVï¼‰
        steps : int
            Maximum number of iterations in the surrogate model.
        trajectory: string
            Filename to store the output.
        acquisition : string
            Acquisition function. 
            é‡‡é›†å‡½æ•°åç§°ï¼ˆå†³å®šç”¨ GP çš„å“ªä¸ªå‡†åˆ™å»é€‰æ ·æœ¬ï¼‰ï¼Œåœ¨æ­¤æ–¹æ³•å‰å·²ä¿å­˜åœ¨ self.acq
        dt : float
            dt parameter for MDMin.
        ml_steps: int 
            Maximum number of steps for the NEB optimization on the
            predicted landscape. 
            åœ¨é¢„æµ‹çš„ï¼ˆç”± GP æä¾›çš„ï¼‰åŠ¿èƒ½é¢ä¸Šåš NEB ä¼˜åŒ–æ—¶å…è®¸çš„æœ€å¤§æ­¥æ•°ï¼ˆæ—©åœä¸Šé™ï¼‰
        max_step: float
            Early stopping criteria. Maximum uncertainty before stopping the
            optimization in the predicted landscape. 
            åœ¨é¢„æµ‹åŠ¿èƒ½é¢ä¸Šè‹¥ä¸ç¡®å®šåº¦è¶…è¿‡æ­¤å€¼å°±æå‰åœæ­¢ä¼˜åŒ–ï¼ˆå®‰å…¨é˜ˆå€¼ï¼‰
        sequential: boolean
            When sequential is set to True, the ML-NEB algorithm starts
            with only one moving image. After finding a saddle point
            the algorithm adds all the images selected in the MLNEB class
            (the total number of NEB images is defined in the 'n_images' flag).
            True è¡¨ç¤ºé€æ­¥æ·»åŠ  imageï¼ˆå…ˆç”¨ 3 å¼  image æ‰¾ saddleï¼Œå†åŠ å›å®Œæ•´æ•°é‡ï¼‰ï¼Œå¯èŠ‚çº¦è®¡ç®—ä½†æ›´å¤æ‚ã€‚
        full_output: boolean
            Whether to print on screen the full output (True) or not (False).

        Returns
        -------
        Minimum Energy Path from the initial to the final states.

        """
        self.acq = acquisition           # æŠŠé‡‡é›†å‡½æ•°åä¸è¾“å‡ºåå¥½ä¿å­˜åˆ°å®ä¾‹ä¸Šï¼Œåé¢å…¶ä»–å‡½æ•°ä¼šè¯»å– self.acq
        self.fullout = full_output       # æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰

        # Calculate a third point if only known initial & final structures.
        '''
        æ„å›¾ï¼šå¦‚æœåªæœ‰ä¸¤ä¸ªè®­ç»ƒç‚¹ï¼ˆstart & endï¼‰ï¼ŒGP æ— æ³•å¾ˆå¥½åœ°æ‹Ÿåˆè·¯å¾„ã€‚äºæ˜¯é€‰ä¸€ä¸ªâ€œinteresting_pointâ€ï¼ˆæœ‰å¯èƒ½æ˜¯é«˜èƒ½ä¸€ä¾§é è¿‘ä¸­éƒ¨çš„ä½ç½®ï¼‰åšä¸€æ¬¡çœŸå®èƒ½é‡/åŠ›è¯„ä¼°å¹¶æŠŠç»“æœæ·»åŠ åˆ°è®­ç»ƒé›†ï¼ˆeval_and_appendï¼‰ã€‚
        middle çš„è®¡ç®—ä¾æ®ç«¯ç‚¹èƒ½é‡å¤§å°å†³å®šåå‘å“ªä¸€ä¾§ï¼šå¦‚æœèµ·ç‚¹èƒ½é‡æ›´é«˜ï¼Œé€‰æ‹©æ›´é è¿‘èµ·ç‚¹çš„ä¸­é—´é•œåƒï¼ˆ1/3ï¼‰ï¼›å¦åˆ™åå‘2/3ã€‚ç›®çš„æ˜¯å°½æ—©é‡‡æ ·æ›´æœ‰å¯èƒ½å« saddle çš„ä¸€ä¾§ã€‚
        self.interesting_point å­˜çš„æ˜¯æ‰€é€‰ image çš„åæ ‡æ‰å¹³å‘é‡ã€‚
        eval_and_append(self, ...)ï¼šæŠŠç‚¹é€å»çœŸå®è®¡ç®—ï¼ˆASE calculatorï¼‰ï¼ŒæŠŠèƒ½é‡/åŠ›ç»“æœåŠ å…¥ self.list_train, self.list_targets, self.list_gradients ç­‰ï¼ˆå‡½æ•°å†…éƒ¨å®Œæˆè°ƒç”¨ calculatorã€è®¡æ•° fevalã€æ›´æ–° train setï¼‰ã€‚
        æ›´æ–°è¿­ä»£è®¡æ•° self.iter å’Œç»Ÿè®¡åŠ› list_max_abs_forcesï¼Œä¿å­˜è½¨è¿¹/æ‰“å°ä¿¡æ¯ã€‚
        æ³¨æ„ï¼šè¿™ä¸€æ­¥æ˜¯â€œä¸»åŠ¨å­¦ä¹ â€ç­–ç•¥çš„ç¬¬ä¸€æ¬¡é‡‡æ ·ï¼Œç¡®ä¿ GP æœ‰æœ€å°‘æ•°é‡çš„è®­ç»ƒç‚¹å¼€å§‹ã€‚
        '''    
        if len(self.list_targets) == 2:
            middle = int(self.n_images * (2./3.))
            if self.energy_is >= self.energy_fs:
                middle = int(self.n_images * (1./3.))
            self.interesting_point = \
                self.images[middle].get_positions().flatten()

            eval_and_append(self, self.interesting_point) # eval_and_append(self, ...)ï¼šæŠŠç‚¹é€å»çœŸå®è®¡ç®—ï¼ˆASE calculatorï¼‰ï¼ŒæŠŠèƒ½é‡/åŠ›ç»“æœåŠ å…¥  \
                                                          # self.list_train, self.list_targets, self.list_gradients ç­‰ \
                                                          # ï¼ˆå‡½æ•°å†…éƒ¨å®Œæˆè°ƒç”¨ calculatorã€è®¡æ•° fevalã€æ›´æ–° train setï¼‰ã€‚


            self.iter += 1
            self.max_forces = get_fmax(np.array([self.list_gradients[-1]]))
            self.max_abs_forces = np.max(np.abs(self.max_forces))
            self.list_max_abs_forces.append(self.max_abs_forces)
            print_info_neb(self)

            store_trajectory_neb(self)

        stationary_point_found = False      # åé¢ç”¨äºçŸ¥é“æ˜¯å¦å‘ç°äº†éç‚¹ï¼ˆsaddleï¼‰ï¼Œä»¥ä¾¿åœ¨ sequential æ¨¡å¼ä¸‹æ¢å¤å®Œæ•´ images æ•°ã€‚

        org_n_images = self.n_images        # ä¿å­˜ç”¨æˆ·åŸæ¥æœŸæœ›çš„é•œåƒæ•°ï¼Œä»¥ä¾¿åœ¨ sequential æ¨¡å¼ä¸´æ—¶æ”¹æˆ 3 åèƒ½æ¢å¤ã€‚

        if sequential is True:
            self.n_images = 3

        while True:

            # 1. Train Machine Learning process.
            '''
            è¾“å…¥ï¼šå½“å‰è®­ç»ƒé›†ï¼ˆç»“æ„ç‰¹å¾ listï¼‰ã€ç›®æ ‡èƒ½é‡ã€åŠ›ã€çº¦æŸæ©ç ã€è·¯å¾„é•¿åº¦ã€æ˜¯å¦æ‰“å°å®Œæ•´è¾“å‡ºã€‚
            è¾“å‡ºï¼šself.gpï¼ˆè®­ç»ƒå¥½çš„ Gaussian Process ä»£ç†ï¼Œç”¨æ¥é¢„æµ‹ä»»æ„ image çš„èƒ½é‡/åŠ›ä¸ä¸ç¡®å®šåº¦ï¼‰ä¸ self.max_targetï¼ˆç”¨äºç¼©æ”¾èƒ½é‡ç›®æ ‡çš„æ•°å€¼ï¼ŒGP training å¯èƒ½ä¼šè¿”å›å½’ä¸€åŒ–å°ºåº¦æˆ–è¯„ä¼°è¯¯å·®çš„æœ€å¤§å€¼ï¼‰ã€‚
            è¿™ä¸€æ­¥æ˜¯ ML-NEB çš„æ ¸å¿ƒï¼šæ›´æ–°ä»£ç†æ¨¡å‹ä½¿å…¶èƒ½åœ¨è·¯å¾„ä¸Šé¢„æµ‹èƒ½é‡/åŠ›ã€‚
            '''
            self.gp, self.max_target = \
                train_gp_model(self.list_train, self.list_targets,
                               self.list_gradients, self.index_mask,
                               self.path_distance, self.fullout)

            # 2. Setup and run ML NEB:
            if self.fullout is True:
                parprint('Max number steps:', ml_steps)
            ml_cycles = 0      # æ§åˆ¶åœ¨ä»£ç†ç©ºé—´ä¸Šå°è¯•ä¸åŒçš„èµ·å§‹è·¯å¾„ï¼ˆç¬¬ä¸€æ¬¡ç”¨åˆå§‹ pathï¼Œç¬¬äºŒæ¬¡ç”¨æœ€è¿‘é¢„æµ‹ path ç­‰ï¼‰ã€‚
                               # ç›®çš„ï¼šç”¨å¤šæ¬¡ä¸åŒèµ·ç‚¹åšä¼˜åŒ–ï¼Œé¿å…è¢«æŸä¸ªç³Ÿç³•çš„èµ·ç‚¹å¡ä½

            while True:        # ML-NEB å†…å±‚å¾ªç¯ï¼šåœ¨predicted landscape ä¸Šä¼˜åŒ–è·¯å¾„

                if stationary_point_found is True:
                    self.n_images = org_n_images

                starting_path = self.images  # Start from last path.         
                                             # è¦ä¼ ç»™ create_ml_neb çš„èµ·å§‹ imagesã€‚ä»£ç é€šè¿‡è¯»å– all_predicted_paths.traj çš„ä¸åŒåˆ‡ç‰‡æ¥æ¢å¤å†å²è·¯å¾„ï¼ˆ0:n æˆ– -n:ï¼‰ã€‚

                if ml_cycles == 0:
                    sp = '0:' + str(self.n_images)
                    if self.fullout is True:
                        parprint('Using initial path.')
                    starting_path = read('./all_predicted_paths.traj', sp)

                if ml_cycles == 1:
                    if self.fullout is True:
                        parprint('Using last predicted path.')
                    sp = str(-self.n_images) + ':'
                    starting_path = read('./all_predicted_paths.traj', sp)

                self.images = create_ml_neb(is_endpoint=self.initial_endpoint,
                                            fs_endpoint=self.final_endpoint,
                                            images_interpolation=starting_path,
                                            n_images=self.n_images,
                                            constraints=self.constraints,
                                            index_constraints=self.index_mask,
                                            gp=self.gp,
                                            scaling_targets=self.max_target,
                                            iteration=self.iter)
                '''
                è¿™é‡Œ create_ml_neb è¢«ä¼ å…¥ gp=self.gpï¼š
                æ„å‘³ç€ç”Ÿæˆçš„ self.images ä¼šå¸¦ä¸Š GP çš„é¢„æµ‹ä¿¡æ¯ï¼ˆä¾‹å¦‚æŠŠ GP é¢„æµ‹çš„èƒ½é‡/åŠ›å†™åˆ° image çš„ info å­—æ®µæˆ–æ›´æ–° self.uncertainty_pathã€self.e_pathï¼‰ã€‚
                self.images å˜æˆâ€œå¸¦æœ‰ GP é¢„æµ‹å’Œä¸ç¡®å®šåº¦çš„è·¯å¾„â€
                '''

                # Test before optimization: åœ¨ä¼˜åŒ–å‰åšæµ‹è¯•ï¼ˆç”¨ GP é¢„æµ‹æ£€æŸ¥ä¸ç¡®å®šåº¦ï¼‰

                for i in self.images: 
                '''
                å¯¹æ¯ä¸ª image è°ƒç”¨ i.get_potential_energy() ä¼šè§¦å‘ GP çš„é¢„æµ‹
                ï¼ˆå› ä¸ºè¿™äº› images çš„ calculator/energy å¯èƒ½è¢«æ›¿æ¢æˆ GP predictor æˆ– create_ml_neb å·²æŠŠé¢„æµ‹å†™å…¥ image infoï¼‰
                '''
                    i.get_potential_energy()
                    get_results_predicted_path(self)               # è¯»å– GP åœ¨æ•´æ¡è·¯å¾„ä¸Šçš„é¢„æµ‹ç»“æœã€å¡«å…… self.e_pathï¼ˆé¢„æµ‹èƒ½é‡æ•°ç»„ï¼‰å’Œ self.uncertainty_pathï¼ˆæ¯å¼ å›¾ç‰‡çš„ä¸ç¡®å®šæ€§ï¼‰ï¼Œå¹¶è®¡ç®—å…¶å®ƒæ´¾ç”Ÿé‡ã€‚
                    unc_ml = np.max(self.uncertainty_path[1:-1])   # å–è·¯å¾„å†…éƒ¨ï¼ˆä¸åŒ…æ‹¬ç«¯ç‚¹ï¼‰çš„æœ€å¤§ä¸ç¡®å®šæ€§ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚

                if unc_ml >= max_step:                             # ï¼ˆä¸ç¡®å®šåº¦å¤ªå¤§ï¼‰ï¼Œåˆ™æå‰åœæ­¢å½“å‰ ML-NEB å†…å±‚å¾ªç¯ï¼ˆå®‰å…¨ç­–ç•¥ï¼špredicted landscape å¤ªä¸å¯é æ— æ³•ç»§ç»­ä¼˜åŒ–ï¼‰ã€‚
                    if self.fullout is True:
                        parprint('Maximum uncertainty reach in initial path.')
                        parprint('Early stop.')
                    break

                # Perform NEB in the predicted landscape. åœ¨predicted landscapeä¸Šç”¨ NEB + MDMin ä¼˜åŒ–ï¼ˆcheapï¼Œå› ä¸ºç”¨ GP é¢„æµ‹èƒ½é‡/åŠ›ï¼‰
                ml_neb = NEB(self.images, climb=True,
                             method=self.neb_method,
                             k=self.spring)                 # ç”¨ ASE çš„ NEB å¯¹è±¡æ„é€  NEB ä¼˜åŒ–é—®é¢˜ï¼Œclimb=True è¡¨ç¤ºå¯ç”¨ climbing-imageï¼ˆç”¨äºå‡†ç¡®å¯»æ‰¾éç‚¹çš„å¢å¼ºç­–ç•¥ï¼‰ã€‚
                                                            # ä½†æ³¨æ„ï¼šè¿™é‡Œçš„ self.images èƒ½é‡/åŠ›æ˜¯æ¥è‡ª GP é¢„æµ‹ï¼Œè€Œä¸æ˜¯æ˜‚è´µçš„ DFTã€‚
              if self.fullout is True:
                    parprint('Optimizing ML CI-NEB using dt:', dt)
                neb_opt = MDMin(ml_neb, dt=dt, logfile=None) # MDMinï¼šä¸€ç§åŸºäºåˆ†å­åŠ¨åŠ›å­¦çš„å±€éƒ¨æœ€å°åŒ–å™¨ï¼ˆæ¨¡æ‹ŸåŠ¨åŠ›å­¦ç„¶åèƒ½é‡æœ€å°åŒ–ï¼‰ï¼Œç”¨äºä¼˜åŒ– NEBã€‚
                if full_output is True:
                    neb_opt = MDMin(ml_neb, dt=dt)

                # ML ä¼˜åŒ–å¾ªç¯ï¼ˆåœ¨predicted landscapeä¸Šåå¤åšå°æ­¥å¹¶æ£€æµ‹ï¼‰
                ml_converged = False
                n_steps_performed = 0
                while ml_converged is False:
                    # Save prev. positions:
                    prev_save_positions = []

                    for i in self.images:        # å…ˆæŠŠå½“å‰æ‰€æœ‰ image çš„ä½ç½®ä¿å­˜åˆ° prev_save_positionsï¼ˆä¾¿äºåœ¨æ£€æµ‹åˆ°é”™è¯¯æ—¶å›é€€ï¼‰ã€‚
                        prev_save_positions.append(i.get_positions())

                    neb_opt.run(fmax=(fmax * 0.85), steps=1)  # neb_opt.run(fmax=..., steps=1) æ¯æ¬¡è¿è¡Œä¸€æ­¥æˆ–å‡ æ­¥ã€‚
                                                              # åšä¸€æ­¥ NEB ä¼˜åŒ–ï¼ˆåœ¨ GP çš„é¢„æµ‹åŠ›åœºä¸Šï¼‰ã€‚æ³¨æ„ç”¨ 0.85Ã—fmax ä½œä¸ºä¼˜åŒ–é˜ˆï¼Œè¡¨ç¤ºåœ¨predicted landscapeä¸Šç¨å¾®ä¸¥æ ¼ä¸€äº›
                    neb_opt.nsteps = 0

                    n_steps_performed += 1
                    get_results_predicted_path(self)          # æ›´æ–° n_steps_performed å¹¶é‡æ–°è°ƒç”¨ get_results_predicted_path(self) æ›´æ–°é¢„æµ‹èƒ½é‡/uncertainty
                    unc_ml = np.max(self.uncertainty_path[1:-1])
                    e_ml = np.max(self.e_path[1:-1])          # è·¯å¾„å†…æœ€å¤§é¢„æµ‹èƒ½é‡ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦é¢„æµ‹å‡ºç°å¼‚å¸¸é«˜èƒ½ï¼‰ã€‚


                    # å®‰å…¨æ£€æŸ¥ / æå‰ç»ˆæ­¢æ¡ä»¶ï¼š
                    if e_ml >= self.max_target + 0.2:         #ï¼ˆé¢„æµ‹çš„è·¯å¾„èƒ½é‡é«˜äºç«¯ç‚¹èƒ½é‡å°ºåº¦å¤ªå¤šï¼‰ï¼Œè¯´æ˜ GP åœ¨è¿™ä¸ªåŒºåŸŸå¯èƒ½å‘æ•£æˆ–å‡ºé”™ â†’ å›é€€åˆ° prev_save_positions å¹¶ç»“æŸ ML ä¼˜åŒ–å¾ªç¯ï¼ˆä¸æŠŠä¸å¯é é¢„æµ‹ä½œä¸ºçœŸå®ç»“æœï¼‰
                        for i in range(0, self.n_images):
                            self.images[i].positions = prev_save_positions[i]
                        if self.fullout is True:
                            parprint('Pred. energy above max. energy. '
                                     'Early stop.')
                        ml_converged = True

                    if unc_ml >= max_step:                    # ï¼ˆé¢„æµ‹ä¸ç¡®å®šæ€§è¿‡å¤§ï¼‰â†’ å›é€€å¹¶ç»“æŸ ML ä¼˜åŒ–å¾ªç¯
                        for i in range(0, self.n_images):
                            self.images[i].positions = prev_save_positions[i]
                        if self.fullout is True:
                            parprint('Maximum uncertainty reach. Early stop.')
                        ml_converged = True
                    if neb_opt.converged():                   # å¦‚æœ neb_opt.converged() â†’ æˆåŠŸæ”¶æ•›äºpredicted landscapeçš„å±€éƒ¨æå€¼ â†’ ml_converged = Trueï¼ˆç»“æŸå¾ªç¯å¹¶ç»§ç»­ä¸‹ä¸€æ­¥æµç¨‹ï¼‰
                        ml_converged = True

                    if np.isnan(ml_neb.emax):                 # å¦‚æœ NEB çš„æœ€å¤§èƒ½é‡å‡ºç° NaNï¼ˆæ•°å€¼ä¸ç¨³å®šï¼‰ï¼Œåˆ™æŠŠ images æ¢å¤ä¸ºä¹‹å‰ä¿å­˜åˆ°ç£ç›˜çš„è·¯å¾„ï¼Œè®¾ç½® n_steps_performed=10000ï¼ˆå¼ºåˆ¶è·³å‡ºå¹¶è§¦å‘å¤±è´¥è·¯å¾„ï¼‰ã€‚
                        sp = str(-self.n_images) + ':'
                        self.images = read('./all_predicted_paths.traj', sp)
                        for i in self.images:
                            i.get_potential_energy()
                        n_steps_performed = 10000

                    if n_steps_performed > ml_steps-1:         # å¦‚æœå¾ªç¯æ­¥æ•°è¶…è¿‡ ml_steps é™åˆ¶ï¼Œä¹Ÿç»ˆæ­¢ï¼ˆå®‰å…¨ä¸Šé™ï¼‰ã€‚
                        if self.fullout is True:
                            parprint('Not converged yet...')
                        ml_converged = True

                    '''
                    ä»¥ä¸Šï¼Œæ•´ä½“ç›®çš„ï¼šåœ¨ cheap çš„ GP åŠ¿ä¸Šå°½é‡æŠŠè·¯å¾„ä¼˜åŒ–åˆ°ç¨³å®šçŠ¶æ€ï¼ˆèŠ‚çœçœŸå®è®¡ç®—ï¼‰ï¼Œä½†æ¯æ­¥éƒ½åšä¸¥æ ¼å®‰å…¨æ£€æŸ¥ä»¥å… GP çš„é”™è¯¯é¢„æµ‹å¯¼è‡´è¯¯å¯¼ã€‚
                    '''

                if n_steps_performed <= ml_steps-1:  # å·²ç»åœ¨predicted landscapeä¸ŠæˆåŠŸä¼˜åŒ–ï¼ˆæˆ–æå‰å®‰å…¨åœï¼‰ï¼Œè·³å‡ºå†…å±‚å¾ªç¯
                    if self.fullout is True:
                        parprint('Converged opt. in the predicted landscape.')
                    break

                ml_cycles += 1
                if self.fullout is True:
                    parprint('ML cycles performed:', ml_cycles)

                if ml_cycles == 2:                    # å¤šæ¬¡ ML ä¼˜åŒ–å¤±è´¥ â†’ æ”¾å¼ƒå½“å‰è®¾ç½®ï¼Œé€€å‡ºå†…å±‚å¾ªç¯
                '''
                è‹¥åœ¨å…è®¸æ­¥æ•°å†…æ”¶æ•›æˆåŠŸï¼ˆæˆ–é€šè¿‡æ—©åœå®‰å…¨é€€å‡ºï¼‰ï¼Œè·³å‡ºå†…å±‚å¾ªç¯ï¼›ml_cycles æ§åˆ¶å°è¯•æ¬¡æ•°ï¼Œè‹¥å°è¯•å¤ªå¤šæ¬¡ä»ä¸å¯è¡Œï¼Œåˆ™è®¤ä¸º ML æµç¨‹ä¸å¯é ï¼ˆå¯èƒ½éœ€è¦æ¢æ’å€¼æˆ–é•œåƒæ•°ï¼‰ï¼Œäºæ˜¯æ”¾å¼ƒï¼ˆé˜²æ­¢æ­»å¾ªç¯ï¼‰ã€‚
                '''
                    if self.fullout is True:
                        parprint('ML process not optimized...not safe...')
                        parprint('Change interpolation or numb. of images.')
                    break
                  

            # 3. Get results from ML NEB using ASE NEB Tools:   # ä»é¢„æµ‹è·¯å¾„æ”¶é›†ç»“æœ
            # See https://wiki.fysik.dtu.dk/ase/ase/neb.html

            self.interesting_point = []                         # æŠŠ self.interesting_point æ¸…ç©ºï¼ˆç¡®ä¿æœ¬è½®é€šè¿‡é‡‡é›†å‡½æ•°æ¥è®¾å®šï¼‰

            # Get fit of the discrete path.
            get_results_predicted_path(self)                    # è®© GP çš„é¢„æµ‹/åŒ…è£…å™¨æŠŠæ•´æ¡è·¯å¾„ä¸Šçš„é¢„æµ‹èƒ½é‡ self.e_path å’Œä¸ç¡®å®šåº¦ self.uncertainty_path å¡«å¥½ï¼ˆé•¿åº¦ = n_imagesï¼‰ã€‚è¿™ä¸€æ­¥å¿…é¡»å…ˆåšâ€”â€”åé¢é‡‡é›†å‡½æ•°éƒ½åŸºäºè¿™ä¸¤ä¸ªæ•°ç»„åšå†³ç­–ã€‚

            pred_plus_unc = np.array(self.e_path[1:-1]) + np.array(
                                                   self.uncertainty_path[1:-1])
            '''
            pred_plus_unc:
            å¯¹å†…éƒ¨ imagesï¼ˆä¸å«ç«¯ç‚¹ï¼‰æ„é€  predicted energy + uncertainty çš„æ•°ç»„ã€‚
            ç±»å‹/å½¢çŠ¶ç¤ºä¾‹ï¼šè‹¥ n_images = 7ï¼Œåˆ™ self.e_path é•¿åº¦ 7ï¼Œself.e_path[1:-1] é•¿åº¦ 5ï¼›pred_plus_unc ä¹Ÿæ˜¯é•¿åº¦ 5 çš„ 1D np.arrayã€‚
						å«ä¹‰ï¼šè¿™æ˜¯å¸¸ç”¨çš„é‡‡é›†å‡†åˆ™ï¼ˆupper confidence bound çš„ç®€åŒ–ï¼‰â€”â€”å…¼é¡¾é«˜é¢„æµ‹èƒ½é‡ï¼ˆå¯èƒ½æ˜¯éç‚¹ï¼‰ä¸é«˜ä¸ç¡®å®šåº¦ï¼ˆå€¼å¾—é‡‡æ ·ï¼‰ã€‚
            '''

            # 4. Select next point to train (acquisition function): Acquisitionï¼ˆé€‰æ‹©ä¸‹ä¸€ä¸ªè¦åšçœŸå®è®¡ç®—çš„ imageï¼‰
						'''
						ä¸‹é¢ä¸€å¤§å—æ˜¯ä¸åŒ self.acqï¼ˆacquisition functionï¼‰çš„å…·ä½“é€»è¾‘ã€‚
						å…ˆè¯´æ˜æ€»ä½“åŸåˆ™ï¼šè¿™äº›é‡‡é›†å‡½æ•°çš„ç›®æ ‡æ˜¯åœ¨â€œæ¢ç´¢ï¼ˆhigh uncertaintyï¼‰â€ä¸â€œåˆ©ç”¨ï¼ˆhigh predicted energyï¼‰â€ä¹‹é—´æƒè¡¡ï¼ŒæŒ‘é€‰ä¸‹ä¸€å¼  image åšçœŸå® expensive è¯„ä¼°ï¼Œä»è€Œæ”¹è¿› GPã€‚

						é€šç”¨æ˜ å°„è§„åˆ™ï¼š
						self.uncertainty_path[1:-1] é•¿åº¦ m = n_images-2ï¼Œç´¢å¼• 0..m-1 å¯¹åº” self.images[1]..self.images[-2]ã€‚
						å½“ä½ çœ‹åˆ° self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])ï¼Œå®ƒè¿”å› jï¼ˆ0..m-1ï¼‰ï¼›çœŸæ­£çš„ Atoms æ˜¯ self.images[1:-1][j]ã€‚
						.get_positions().flatten()ï¼šæŠŠè¢«é€‰ image çš„åŸå­åæ ‡æ‹¿å‡ºæ¥å¹¶æ‰å¹³åŒ–ï¼Œä½œä¸º interesting_point ä¼ ç»™ eval_and_append
						'''

            # Acquisition function 1:
						'''
            äº¤æ›¿ç­–ç•¥ï¼šå¶æ•°è¿­ä»£åšæ¢ç´¢ï¼ˆuncertaintyï¼‰ï¼Œå¥‡æ•°åšåˆ©ç”¨ï¼ˆpred_plus_uncï¼‰ã€‚
						ç›®çš„æ˜¯äº¤æ›¿è¡¥æ•°æ®ï¼Œä¸€æ¬¡å‡ä¸ç¡®å®šæ€§ã€ä¸€æ¬¡é€¼è¿‘é«˜èƒ½åŒºï¼ˆå¯èƒ½çš„ saddleï¼‰ã€‚
						'''
            if self.acq == 'acq_1':
                # Behave like acquisition 4...
                # Select image with max. uncertainty.
                if self.iter % 2 == 0:                                         # è½®åˆ°â€œæ¢ç´¢â€ï¼šé€‰æœ€å¤§ä¸ç¡®å®šåº¦çš„ image
                    self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                    self.interesting_point = self.images[1:-1][
                                    self.argmax_unc].get_positions().flatten()

                # Select image with max. predicted value.
                if self.iter % 2 == 1:                                         # è½®åˆ°â€œåˆ©ç”¨â€ï¼šé€‰ pred+unc æœ€å¤§çš„ image
                    self.argmax_unc = np.argmax(pred_plus_unc)
                    self.interesting_point = self.images[1:-1][
                                int(self.argmax_unc)].get_positions().flatten()

            # Acquisition function 2:
						'''
						ä¼˜å…ˆæ¢ç´¢ï¼ˆæœ€å¤§ä¸ç¡®å®šåº¦ï¼‰ï¼›ä½†å½“å…¨è·¯å¾„çš„ä¸ç¡®å®šåº¦éƒ½å°äºé˜ˆ unc_convergence æ—¶ï¼Œè½¬ä¸ºåˆ©ç”¨ï¼ˆæŒ‘é€‰å…·æœ‰æœ€å¤§ pred+unc çš„ç‚¹ï¼‰ã€‚
						å«ä¹‰ï¼šå…ˆæŠŠ GP çš„ä¸ç¡®å®šåº¦é™ä¸‹æ¥ï¼Œç¡®ä¿é¢„æµ‹å¯ä¿¡ï¼Œç„¶åå†å»æ‰¾é«˜èƒ½ç‚¹ã€‚
						'''
            if self.acq == 'acq_2':
                # Step1. Select image with max. uncertainty.
                self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                self.interesting_point = self.images[1:-1][
                                  self.argmax_unc].get_positions().flatten()

                # Srep2. Select image with max. predicted value. è½¬ä¸ºåˆ©ç”¨
                if np.max(self.uncertainty_path[1:-1]) < unc_convergence:

                    self.argmax_unc = np.argmax(pred_plus_unc)
                    self.interesting_point = self.images[1:-1][
                                int(self.argmax_unc)].get_positions().flatten()

            # Acquisition function 3:
						'''
						å…ˆæŠŠ uncertainty é™åˆ°é˜ˆä¸‹ï¼›è¾¾åˆ°ååˆ‡å› acq_1 çš„äº¤æ›¿ç­–ç•¥ã€‚
						è·Ÿ acq_2 å¾ˆåƒï¼Œä½† acq_3 è¾¾åˆ°æ”¶æ•›åä»ç„¶äº¤æ›¿ï¼ˆä¸æ˜¯ç›´æ¥ä¸€ç›´ç”¨ pred+uncï¼‰
						'''
            if self.acq == 'acq_3':
                # Select image with max. uncertainty.
                self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                self.interesting_point = self.images[1:-1][
                                    self.argmax_unc].get_positions().flatten()

                # When reached certain uncertainty apply acq. 1.
                if np.max(self.uncertainty_path[1:-1]) < unc_convergence:
                    # Select image with max. uncertainty.
                    if self.iter % 2 == 0:
                        self.argmax_unc = \
                                        np.argmax(self.uncertainty_path[1:-1])
                        self.interesting_point = self.images[1:-1][
                                    self.argmax_unc].get_positions().flatten()
                    # Select image with max. predicted value.
                    if self.iter % 2 == 1:
                        self.argmax_unc = np.argmax(pred_plus_unc)
                        self.interesting_point = self.images[1:-1][
                                int(self.argmax_unc)].get_positions().flatten()

            # Acquisition function 4 (from acq 2):
						'''
						å’Œ acq_1 å¾ˆåƒï¼Œä½†åœ¨æ£€æµ‹åˆ° stationary_point_foundï¼ˆç®—æ³•å‘ç°äº†ç¨³å®šç‚¹ï¼‰æ—¶åˆ‡æ¢åˆ° acq_2 çš„é€»è¾‘ï¼ˆå³ä¼˜å…ˆæŠŠä¸ç¡®å®šåº¦é™åˆ°é˜ˆä¸‹å†é‡‡æ ·ï¼‰ã€‚
						'''
            if self.acq == 'acq_4':
						# ==== å¶æ•°/å¥‡æ•° ğŸ”
                # Select image with max. uncertainty.
                if self.iter % 2 == 0:
                    self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                    self.interesting_point = self.images[1:-1][
                                    self.argmax_unc].get_positions().flatten()

                # Select image with max. predicted value.
                if self.iter % 2 == 1:
                    self.argmax_unc = np.argmax(pred_plus_unc)
                    self.interesting_point = self.images[1:-1][
                                int(self.argmax_unc)].get_positions().flatten()

								
                # If stationary point is found behave like acquisition 2...ï¼ˆç®—æ³•å‘ç°äº†ç¨³å®šç‚¹ï¼‰æ—¶åˆ‡æ¢åˆ° acq_2 çš„é€»è¾‘ï¼ˆå³ä¼˜å…ˆæŠŠä¸ç¡®å®šåº¦é™åˆ°é˜ˆä¸‹å†é‡‡æ ·ï¼‰ã€‚
                if stationary_point_found is True:
                    # Select image with max. uncertainty.
                    self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                    self.interesting_point = self.images[1:-1][
                                     self.argmax_unc].get_positions().flatten()

                    # Select image with max. predicted value.
                    if np.max(self.uncertainty_path[1:-1]) < unc_convergence:

                        self.argmax_unc = np.argmax(pred_plus_unc)
                        self.interesting_point = self.images[1:-1][
                                int(self.argmax_unc)].get_positions().flatten()

            # Acquisition function 5 (From acq 3):
						# å…ˆé€‰ä¸ç¡®å®šåº¦ï¼ˆåƒ acq_2/3/4ï¼‰ï¼Œå½“ä¸ç¡®å®šåº¦è¶³å¤Ÿä½åï¼Œè¿›å…¥äº¤æ›¿é‡‡æ ·ï¼›
						# åœ¨é‡åˆ° stationary point æ—¶è¡¨ç°åƒ acq_2ã€‚
						# è¿™å¸¸è¢«ç”¨ä½œâ€œç¨³å¥æ¢ç´¢å…ˆè¡Œï¼Œä¹‹åæ··åˆç­–ç•¥â€çš„æŠ˜è¡·ã€‚
            if self.acq == 'acq_5':
                # Select image with max. uncertainty.
                self.argmax_unc = np.argmax(self.uncertainty_path[1:-1])
                self.interesting_point = self.images[1:-1][
                                 self.argmax_unc].get_positions().flatten()

                # When reached certain uncertainty apply acq. 1.
                if np.max(self.uncertainty_path[1:-1]) < unc_convergence:
                    # Select image with max. uncertainty.
                    if self.iter % 2 == 0:
                        self.argmax_unc = \
                                     np.argmax(self.uncertainty_path[1:-1])
                        self.interesting_point = self.images[1:-1][
                                 self.argmax_unc].get_positions().flatten()

                    # Select image with max. predicted value.
                    if self.iter % 2 == 1:
                        self.argmax_unc = np.argmax(pred_plus_unc)
                        self.interesting_point = self.images[1:-1][
                            int(self.argmax_unc)].get_positions().flatten()
                    # If stationary point is found behave like acq. 2.
                    if stationary_point_found is True:
                        # Select image with max. uncertainty.
                        self.argmax_unc = \
                                     np.argmax(self.uncertainty_path[1:-1])
                        self.interesting_point = self.images[1:-1][
                                 self.argmax_unc].get_positions().flatten()

                    # Select image with max. predicted value.
                    if np.max(self.uncertainty_path[1:-1]) < \
                                                           unc_convergence:

                        self.argmax_unc = np.argmax(pred_plus_unc)
                        self.interesting_point = \
                            self.images[1:-1][int(
                                self.argmax_unc)].get_positions().flatten()

						# ================================
            # 5. Add a new training point and evaluate it. çœŸå€¼è¯„ä¼°ï¼šç”¨çœŸå®è®¡ç®—å™¨ç®—å‡º selected point
            if self.fullout is True:
                parprint('Performing evaluation on the real landscape...')
            eval_and_append(self, self.interesting_point)
						'''
						eval_and_append:
						æŠŠ self.interesting_pointï¼ˆæ‰å¹³åŒ–ä½ç½®ï¼‰æ„å»ºæˆ–é€‰å‡ºå¯¹åº”çš„ Atomsï¼Œ
						æŠŠ ase_calcï¼ˆVASP/GPAW/EMT ç­‰ï¼‰è®¾ç½®ä¸Šå»å¹¶è¿è¡ŒçœŸå®è®¡ç®—ï¼Œæ‹¿åˆ° E å’Œ Fï¼Œ
						å°†è¯¥æ ·æœ¬è½¬æ¢æˆ GP çš„ feature å¹¶è¿½åŠ åˆ° self.list_train, self.list_targets, self.list_gradientsã€‚åŒæ—¶æ›´æ–° self.fevalï¼ˆçœŸå®èƒ½é‡/åŠ›è°ƒç”¨è®¡æ•°ï¼‰ã€‚
						'''
            self.iter += 1             # è®¡æ•°ä¸€æ¬¡ä¸»åŠ¨å­¦ä¹ è¿­ä»£ï¼ˆå·²è¯„ä¼°ä¸€ä¸ªçœŸå®ç‚¹ï¼‰
            if self.fullout is True:
                parprint('Single-point calculation finished.')

            # 6. Store results.       # å­˜å‚¨ä¸ç»Ÿè®¡ï¼ˆæŠŠæ–°è¯„ä¼°çš„ç»“æœå†™å…¥æ—¥å¿—/æ–‡ä»¶å¹¶è®¡ç®—åŠ›ä¸èƒ½éšœï¼‰
						# self.e_path å·²è¢« get_results_predicted_path(self) æ›´æ–°ï¼ˆä½†æ³¨æ„ï¼šæ­¤åˆ» self.e_path å¯èƒ½æ··åˆäº† GP çš„é¢„æµ‹å’Œæ–°è¿½åŠ ç‚¹çš„çœŸå€¼ï¼Œå–å†³äºå®ç°ç»†èŠ‚ä¸æ˜¯å¦åœ¨ eval åé‡æ–°è°ƒç”¨ get_results_predicted_path
            parprint('\n')
            self.energy_forward = np.max(self.e_path) - self.e_path[0]        # ä»èµ·ç‚¹èƒ½é‡åˆ°è·¯å¾„æœ€é«˜ç‚¹çš„èƒ½é‡å·®ï¼ˆæ­£å‘ barrierï¼‰ï¼šmax(e_path) - e_path[0]
            self.energy_backward = np.max(self.e_path) - self.e_path[-1]      # ä»ç»ˆç‚¹åˆ°æœ€é«˜ç‚¹çš„èƒ½é‡å·®ï¼ˆåå‘ barrierï¼‰ï¼šmax(e_path) - e_path[-1]
            self.max_forces = get_fmax(np.array([self.list_gradients[-1]]))   # æœ€åè¢«è¿½åŠ ï¼ˆçœŸå® evalï¼‰çš„åŠ›æ•°ç»„ï¼›get_fmax(np.array([ ... ])) è¿”å›è¯¥ç»“æ„çš„ fmaxï¼ˆæ³¨æ„åŒ…è£…ä¸º batchï¼‰
            self.max_abs_forces = np.max(np.abs(self.max_forces))						  # np.max(np.abs(...)) å¾—åˆ°æ ‡é‡æ­£å€¼

            print_info_neb(self)        # æ‰“å°å½“å‰è¿­ä»£çš„æ‘˜è¦ï¼ˆèƒ½éšœã€fmaxã€ä¸ç¡®å®šåº¦ç­‰ï¼‰ã€‚
            store_results_neb(self)
            store_trajectory_neb(self)  # æŠŠç»“æœå†™åˆ° CSV/trajectory ç­‰æ–‡ä»¶ï¼Œä¾¿äºåç»­åˆ†æã€ç»˜å›¾æˆ–é‡å¯ã€‚

            # 7. Check convergence:

            if self.max_abs_forces <= fmax:
                stationary_point_found = True  # åªé’ˆå¯¹è¿™ä¸€ä¸ªimageï¼Œè€Œä¸æ˜¯æ‰€æœ‰images

            # Check whether the evaluated point is a stationary point.
            if self.max_abs_forces <= fmax and self.n_images == org_n_images:   # # è®­ç»ƒ final GPï¼Œæ›´æ–°è·¯å¾„ï¼Œå†™æ–‡ä»¶ï¼ŒæŠ¥æˆåŠŸï¼Œbreakï¼› ç¬¬äºŒä¸ªåˆ¤æ–­éœ€è¦ self.n_images == org_n_imagesï¼šç¡®ä¿å¦‚æœä½ åœ¨ sequential æ¨¡å¼ä¸´æ—¶ç¼©å°è¿‡ image æ•°ï¼ˆå…ˆç”¨ 3 å¼ ï¼‰ï¼Œå·²æ¢å¤åˆ°åŸå§‹é•œåƒæ•°æ‰ç®—çœŸæ­£å®Œæˆã€‚å¦åˆ™å¯èƒ½è¯¯ä»¥ä¸ºåœ¨ 3 å¼ å›¾ä¸Šæ‰¾åˆ°äº†éç‚¹è€Œç»ˆæ­¢ã€‚
                msg = "Congratulations! Stationary point is found! "
                msg2 = "Check the file 'evaluated_structures.traj' using ASE."
                parprint(msg+msg2)

                if np.max(self.uncertainty_path[1:-1]) < unc_convergence:
                    # Save results of the final step (converged):
										'''
										å†æ¬¡è®­ç»ƒ GPï¼ˆç¡®ä¿æœ‰æœ€æ–°è®­ç»ƒé›†ï¼‰ï¼Œé‡æ–°è®¡ç®— get_results_predicted_path(self)ï¼ˆæ›´æ–° self.e_path/uncertaintyï¼‰ï¼Œä¿å­˜ç»“æœæ–‡ä»¶å¹¶å†™æœ€åçš„ trajectoryï¼Œæ¸…é™¤ä¸´æ—¶æ–‡ä»¶å¹¶ breakï¼ˆè·³å‡ºä¸»å¾ªç¯ï¼Œç»“æŸç®—æ³•ï¼‰
										'''
                    self.gp, self.max_target = \
                        train_gp_model(self.list_train, self.list_targets,
                                       self.list_gradients, self.index_mask,
                                       self.path_distance, self.fullout)
                    get_results_predicted_path(self)
                    store_results_neb(self)
                    msg = "Congratulations! Your ML NEB is converged. "
                    msg2 = "If you want to plot the ML NEB predicted path you "
                    msg3 = "should check the files 'results_neb.csv' "
                    msg4 = "and 'results_neb_interpolation.csv'."
                    parprint(msg+msg2+msg3+msg4)
                    # Last path.
                    write(trajectory, self.images)
                    parprint('The optimized predicted path can be found in: ',
                             trajectory)
                    # Clean up:
                    if world.rank == 0:
                        os.remove('./last_predicted_path.traj')
                        os.remove('./all_predicted_paths.traj')
                    break

            # Break if reaches the max number of iterations set by the user.
            if steps <= self.iter:
                parprint('Maximum number iterations reached. Not converged.')
                break

        parprint('Number of steps performed in total:',
                 len(self.list_targets)-2)
        print_cite_mlneb()

# =======================================================================
def create_ml_neb(is_endpoint, fs_endpoint, images_interpolation,
                  n_images, constraints, index_constraints,
                  scaling_targets, iteration, gp=None):
    """
    Generates input NEB for the GPR.
		
	  is_endpointï¼šase.Atoms å¯¹è±¡ï¼Œèµ·å§‹ç«¯ç‚¹ç»“æ„ï¼ˆinitial stateï¼‰ã€‚
		fs_endpointï¼šase.Atoms å¯¹è±¡ï¼Œç»ˆç‚¹ç»“æ„ï¼ˆfinal stateï¼‰ã€‚
		images_interpolationï¼šå¯ä»¥æ˜¯ None æˆ– list of ase.Atomsï¼ˆä¸€æ¡å·²æœ‰çš„æ’å€¼è·¯å¾„ï¼‰ï¼›å¦‚æœä¸æ˜¯ Noneï¼Œå‡½æ•°ä¼šæŠŠä¸­é—´ images çš„åæ ‡ä»è¿™é‡Œå–è¿‡æ¥ã€‚
		n_imagesï¼šæ•´æ•°ï¼Œæ€»çš„ image æ•°ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªç«¯ç‚¹ï¼‰ã€‚æ³¨æ„ï¼šä¸­é—´ images çš„ç´¢å¼•æ˜¯ 1 .. n_images-2ã€‚
		constraintsï¼šASE çš„çº¦æŸå¯¹è±¡æˆ– Noneï¼ˆæ¯”å¦‚ FixAtoms(...)ï¼‰ï¼Œè¡¨ç¤ºè¦æ–½åŠ åˆ°æ¯ä¸ª image çš„çº¦æŸï¼ˆå“ªäº›åŸå­ä¸èƒ½åŠ¨ç­‰ï¼‰ã€‚
		index_constraintsï¼šç´¢å¼•æ©ç æˆ–ç´¢å¼•åˆ—è¡¨ï¼Œä¾› ASECalc ä½¿ç”¨ï¼ˆå‘Šè¯‰ GP/é¢„æµ‹å™¨å“ªäº›è‡ªç”±åº¦å‚ä¸ã€æˆ–å“ªäº›è¢«å±è”½ï¼‰ï¼Œç”¨äºåœ¨å»ºæ¨¡/é¢„æµ‹æ—¶å¿½ç•¥è¢«çº¦æŸçš„è‡ªç”±åº¦ã€‚
		scaling_targetsï¼šæ ‡é‡æˆ–å‚æ•°ï¼Œç”¨äºèƒ½é‡/ä¸ç¡®å®šåº¦çš„å½’ä¸€åŒ–æˆ–ç¼©æ”¾ï¼ˆGP é¢„æµ‹æ—¶å¯èƒ½éœ€è¦æŠŠèƒ½é‡ç¼©æ”¾åˆ°ä¸€å®šèŒƒå›´ï¼‰ã€‚
		iterationï¼šæ•´æ•°ï¼Œå½“å‰ä¸»åŠ¨å­¦ä¹ å¾ªç¯/è¿­ä»£ç¼–å·ï¼Œç”¨æ¥æŠŠâ€œå“ªä¸€è½®äº§ç”Ÿçš„é¢„æµ‹â€è®°å½•åˆ°æ¯å¼  image çš„ image.info ä¸­ï¼ˆä¾¿äºè¿½è¸ªï¼‰ã€‚
		gpï¼šå¯é€‰ï¼Œè®­ç»ƒå¥½çš„ Gaussian Processï¼ˆæˆ–å…¶ä»– surrogateï¼‰å¯¹è±¡ï¼›
		å¦‚æœä¼ å…¥ï¼Œå°±æŠŠå®ƒâ€œæŒ‚â€åˆ°ä¸­é—´ images çš„ calculatorï¼ˆé€šè¿‡å°è£…çš„ ASECalcï¼‰ï¼Œç”¨äºåç»­ get_potential_energy()/get_forces() æ—¶è¿”å›é¢„æµ‹å€¼å’Œä¸ç¡®å®šåº¦ã€‚
		è‹¥ gp=Noneï¼ŒASECalc ä»å¯è¢«åˆ›å»ºä½†ä¸å…·æœ‰é¢„æµ‹èƒ½åŠ›ï¼ˆæˆ–è¿”å›ç©º/é»˜è®¤ï¼‰
    """

    # Create ML NEB path:
		'''
		æ–°å»º Python åˆ—è¡¨ imgsï¼Œç¬¬ä¸€ä¸ªå…ƒç´ å°±æ˜¯ä¼ å…¥çš„ is_endpointï¼ˆèµ·ç‚¹ï¼‰ã€‚
		æ³¨æ„è¿™é‡Œç›´æ¥æ”¾äº† is_endpoint å¯¹è±¡çš„å¼•ç”¨ï¼ˆä¸æ˜¯ copyï¼‰ï¼Œå› æ­¤å¦‚æœåé¢ä¿®æ”¹ imgs[0] çš„å±æ€§ä¼šå½±å“åŸ is_endpoint å˜é‡ï¼ˆä½†å¸¸è§åšæ³•æ˜¯ç«¯ç‚¹ç”±å¤–é¢æ§åˆ¶ï¼Œå‡½æ•°åªæ·»åŠ  infoï¼‰
		'''
    imgs = [is_endpoint]    

    # Append labels, uncertainty and iter to the first end-point:
		'''
		image.info æ˜¯ ase.Atoms çš„å­—å…¸ï¼Œç”¨äºå­˜ä»»æ„å…ƒæ•°æ®ã€‚è¿™é‡Œä¸ºç«¯ç‚¹è®¾ç½®ï¼š
		label = 0ï¼šæ ‡è®°è¿™æ˜¯ç¬¬ 0 å¼  imageï¼ˆä¾¿äºåç»­å’Œæ–‡ä»¶/ç´¢å¼•å¯¹åº”ï¼‰ã€‚
		uncertainty = 0.0ï¼šç«¯ç‚¹ä¸è¢« GP é¢„æµ‹ï¼ˆæ˜¯å·²çŸ¥çš„çœŸå®ç«¯ç‚¹ï¼‰ï¼Œè®¾ä¸ç¡®å®šåº¦ä¸º 0ï¼ˆè¡¨ç¤ºå·²çŸ¥ã€æ— é¡»é‡‡æ ·ï¼‰ã€‚
		iterationï¼šæŠŠå½“å‰è¿­ä»£å·å†™è¿›å»ï¼Œä¾¿äºæ—¥å¿—å’Œåç»­è¿½è¸ªâ€œè¿™å¼  image æ˜¯å“ªè½®è¢«ç”Ÿæˆ/é¢„æµ‹çš„â€ã€‚
		å¤‡æ³¨ï¼šç«¯ç‚¹æ²¡æœ‰åœ¨è¿™é‡Œè®¾ç½® set_calculator(ASECalc(...)) :
    æ„å‘³ç€ç«¯ç‚¹é€šå¸¸ç”±å¤–é¢è¢«è®¾ç½®æˆçœŸå®çš„ ASE è®¡ç®—å™¨ï¼ˆå¦‚ VASPï¼‰ï¼Œæˆ–è€…å®ƒä»¬è¢«å½“æˆå›ºå®šå‚è€ƒï¼Œä¸ç”± GP é¢„æµ‹ï¼ˆè¿™æ˜¯åˆç†çš„ï¼šç«¯ç‚¹ä¸€èˆ¬å·²ç»ç”±ç”¨æˆ·æä¾›å¹¶å¯èƒ½è¢«çœŸå®è®¡ç®—è¿‡ï¼‰ã€‚
		'''
    imgs[0].info['label'] = 0
    imgs[0].info['uncertainty'] = 0.0
    imgs[0].info['iteration'] = iteration

		# å¾ªç¯åˆ›å»ºä¸­é—´ imagesï¼ˆ1 ... n_images-2ï¼‰
    for i in range(1, n_images-1):  # éå†ä¸­é—´é•œåƒçš„ç´¢å¼•ï¼ˆä¸åŒ…æ‹¬ç«¯ç‚¹ï¼‰ã€‚i çš„å–å€¼æ˜¯ 1,2,...,n_images-2ã€‚æ³¨æ„ç´¢å¼•ä¸ imgs çš„æœ€ç»ˆä½ç½®ä¸€ä¸€å¯¹åº”ã€‚
        image = is_endpoint.copy()  # ä»¥ is_endpoint ä¸ºæ¨¡æ¿å¤åˆ¶ä¸€ä¸ª Atoms å¯¹è±¡ï¼ˆå¤åˆ¶åŒ…å«åŸå­æ•°ã€å…ƒç´ é¡ºåºã€å•å…ƒæ ¼ã€åŸºå…ƒç­‰ï¼‰ã€‚
                                    # ä¹‹æ‰€ä»¥ç”¨ is_endpoint.copy() è€Œä¸æ˜¯æ–°å»ºï¼Œæ˜¯ä¸ºäº†ä¿è¯æ‰€æœ‰ image çš„å…ƒç´ é¡ºåºã€åŸå­ç§ç±»ä¸æ•°é‡ä¸€è‡´
                                    #ï¼ˆæ’å€¼/èµ‹å€¼æ—¶å¿…é¡»åŸå­ä¸€ä¸€å¯¹åº”ï¼‰ã€‚å¤åˆ¶åªæ˜¯æ‹¿åˆ°ä¸€ä¸ªâ€œç©ºå£³â€å†æŠŠä½ç½®è¦†ç›–ã€‚
        image.info['label'] = i
        image.info['uncertainty'] = 0.0
        image.info['iteration'] = iteration
				'''
				ç»™æ¯ä¸ªä¸­é—´ image è®¾ç½® labelï¼ˆå…¶åœ¨è·¯å¾„ä¸­çš„ç¼–å·ï¼‰ã€åˆå§‹åŒ–ä¸ç¡®å®šåº¦ä¸º 0ï¼ˆåç»­ create_ml_neb + GP predict ä¼šè¦†ç›–å®ƒï¼‰ã€è®°å½•è¿­ä»£å·ã€‚
				'''
				# ======è¿™é‡Œå¾ˆå…³é”®å“¦==========
				'''
				å…³é”®è¯­å¥ â€”â€” æŠŠä¸€ä¸ªå°è£…å™¨è®¡ç®—å™¨ï¼ˆASECalcï¼‰æŒ‚åˆ° image ä¸Šã€‚å«ä¹‰ä¸æ•ˆæœï¼š
				A. ASECalc å¾ˆå¯èƒ½æ˜¯ä¸€ä¸ª wrapperï¼Œä½¿å¾—å½“ä½ è°ƒç”¨ image.get_potential_energy() æˆ– image.get_forces() æ—¶ï¼Œä¼šè°ƒç”¨å†…éƒ¨çš„ gp.predict(...) æ¥è¿”å›ï¼šé¢„æµ‹èƒ½é‡ã€é¢„æµ‹åŠ›ã€ä»¥åŠé¢„æµ‹ä¸ç¡®å®šåº¦ï¼ˆå¦‚æœ gp å¯ç”¨ï¼‰ã€‚
				B. index_constraints å‘Šè¯‰ ASECalc åœ¨é¢„æµ‹æ—¶è¦å±è”½å“ªäº›åŸå­/å“ªäº›è‡ªç”±åº¦ï¼ˆä¸çº¦æŸä¿æŒä¸€è‡´ï¼‰ï¼Œå³ GP åªåœ¨æœªè¢«çº¦æŸçš„è‡ªç”±åº¦ä¸Šè¿›è¡Œé¢„æµ‹/è®­ç»ƒã€‚
				C. scaling_targets ç”¨äºå¯¹èƒ½é‡/ä¸ç¡®å®šåº¦åšç¼©æ”¾ï¼ˆGP è®­ç»ƒä¸é¢„æµ‹é€šå¸¸éœ€è¦æŸç§å½’ä¸€åŒ–å°ºåº¦ï¼‰ã€‚
				D. å¦‚æœ gp æ˜¯ Noneï¼ŒASECalc å¯èƒ½è¿”å›ä¸€ä¸ªå ä½ calculatorï¼ˆä¾‹å¦‚å§‹ç»ˆç»™ NaN æˆ– 0ï¼‰ï¼Œæˆ–ä¸é¢„æµ‹ã€‚è¿™å–å†³ ASECalc çš„å®ç°ç»†èŠ‚ï¼Œä½†è®¾è®¡æ„å›¾æ˜¯æŠŠ GP é¢„æµ‹èƒ½åŠ›æŒ‚åˆ°ä¸­é—´ imagesã€‚
				è¿™æ ·åšçš„ç›®çš„ï¼šåœ¨ ML é˜¶æ®µï¼Œä¸­é—´ images çš„èƒ½é‡/åŠ›éƒ½æ¥è‡ª GPï¼ˆå¿«é€Ÿï¼‰ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½è·‘ DFTï¼ˆæ˜‚è´µï¼‰ã€‚
				'''
        image.set_calculator(ASECalc(gp=gp,
                                     index_constraints=index_constraints,
                                     scaling_targets=scaling_targets))

				'''
				ä¸‹é¢çš„ifè¯­å¥ï¼š
				è‹¥å¤–éƒ¨ç»™äº† images_interpolationï¼ˆä¸€æ¡åˆå§‹è·¯å¾„ï¼Œlist of Atomsï¼‰ï¼Œ
        å°±æŠŠç¬¬ i å¸§çš„åæ ‡å¤åˆ¶ç»™å½“å‰ imageã€‚è¿™å°±æ˜¯æŠŠâ€œæ’å€¼è·¯å¾„â€æ¬åˆ°æ–°åˆ›å»ºçš„ image ä¸Šã€‚
				A. é‡è¦ï¼šimages_interpolation çš„é•¿åº¦ä¸ n_images å¿…é¡»å¯¹åº”ï¼ˆå³ images_interpolation[i] å­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä¼š IndexErrorã€‚é€šå¸¸ images_interpolation é•¿åº¦ = n_imagesã€‚
				B. å¦‚æœ images_interpolation is Noneï¼Œä¸­é—´ image ä»æ˜¯ is_endpoint.copy() çš„åæ ‡ï¼ˆä¹Ÿå°±æ˜¯å’Œèµ·ç‚¹é‡åˆï¼‰ï¼Œä½†é€šå¸¸å‰é¢ä¼šé€šè¿‡å…¶å®ƒæ’å€¼é€»è¾‘åˆ›å»ºåˆé€‚ positionsã€‚
				'''
        if images_interpolation is not None:
            image.set_positions(images_interpolation[i].get_positions())
        image.set_constraint(constraints)
        imgs.append(image)  # æŠŠæ„é€ å¥½çš„ä¸­é—´ imageï¼ˆå« labelã€calculatorã€ä½ç½®ä¸çº¦æŸï¼‰è¿½åŠ åˆ° imgs åˆ—è¡¨ã€‚
			# ======è¿™é‡Œå¾ˆå…³é”®å“¦==========

    # Scale energies (final):
    imgs.append(fs_endpoint)   # æŠŠç»ˆç‚¹ fs_endpoint æ”¾åˆ°åˆ—è¡¨æœ«å°¾ï¼ˆç´¢å¼•ä¸º n_images-1ï¼‰ã€‚
                               # åŒæ ·æ³¨æ„è¿™é‡Œç›´æ¥æ”¾çš„æ˜¯ fs_endpoint çš„å¼•ç”¨è€Œä¸æ˜¯ copyï¼ˆé™¤é fs_endpoint æœ¬èº«æ˜¯ copy å‡ºæ¥çš„ï¼‰

    # Append labels, uncertainty and iter to the last end-point:
    imgs[-1].info['label'] = n_images-1     # ç»™ç»ˆç‚¹æ‰“ä¸Š labelï¼ˆæœ€åä¸€ä¸ªç´¢å¼•ï¼‰ã€‚
    imgs[-1].info['uncertainty'] = 0.0      # ç«¯ç‚¹ä¸ç¡®å®šåº¦è®¾ä¸º 0ï¼ˆç«¯ç‚¹é€šå¸¸æ˜¯å·²çŸ¥/lockedï¼‰ï¼Œè¡¨ç¤ºæ— éœ€é€šè¿‡ GP é¢„æµ‹ã€‚
    imgs[-1].info['iteration'] = iteration  # è®°å½•è¿­ä»£å·ã€‚


		'''
		å¯¹ä¸­é—´ imgï¼šä¸Šè¿°è°ƒç”¨ä¼šè§¦å‘ ASECalc çš„ get_potential_energy() / get_forces()
		           è¿™é‡Œä¼šè°ƒç”¨ gp.predict(...)ï¼ˆè‹¥ gp å·²è®­ç»ƒï¼‰ï¼Œå¾—åˆ°é¢„æµ‹çš„èƒ½é‡/åŠ›/ä¸ç¡®å®šåº¦ï¼ˆå¿«é€Ÿã€cheapï¼‰ã€‚
		å¯¹ç«¯ç‚¹ imgï¼šè‹¥ç«¯ç‚¹æœªè¢«è®¾ç½®ä¸º ASECalcï¼Œåˆ™è°ƒç”¨ä¼šä½¿ç”¨ç«¯ç‚¹å·²æŒ‚è½½çš„çœŸå® calculatorï¼ˆæˆ–æŠ¥é”™ï¼‰ï¼Œé€šå¸¸ç«¯ç‚¹ä¼šåœ¨åˆ«å¤„è¢«å¤„ç†ä¸ºçœŸå®è®¡ç®—å™¨æˆ–è¢«è®¤ä¸ºæ˜¯çœŸå€¼å‚è€ƒã€‚
		'''
    return imgs

# ==================================================
@parallel_function
'''
æ„å‘³ç€è¿™ä¸ªå‡½æ•°å¯èƒ½è¢«å¹¶è¡ŒåŒ–æ‰§è¡Œï¼ˆä¾‹å¦‚é€šè¿‡ MPI åˆ†å‘ï¼‰ï¼Œæˆ–è€…ç»“æœä¼šåœ¨å¤šä¸ªè¿›ç¨‹/çº¿ç¨‹é—´åŒæ­¥ã€‚
å½±å“ï¼šè®­ç»ƒå¯èƒ½åœ¨å¹¶è¡Œç¯å¢ƒä¸‹è¿è¡Œï¼ˆä¾‹å¦‚ä¸åŒè¿›ç¨‹åœ¨æœ¬åœ°è®­ç»ƒ/ååŒä¼˜åŒ–ï¼‰ï¼Œ
æ³¨æ„ gp çš„è¿”å›å¯èƒ½éœ€è¦å¹¿æ’­åˆ°æ‰€æœ‰è¿›ç¨‹ã€‚è°ƒè¯•æ—¶è‹¥åœ¨å•è¿›ç¨‹ç¯å¢ƒçœ‹ä¸åˆ°å¹¶è¡Œè¡Œä¸ºæ²¡é—®é¢˜ã€‚
'''
def train_gp_model(list_train, list_targets, list_gradients, index_mask,
                   path_distance, fullout=False):
    """
    Train Gaussian process
    """
    max_target = np.max(list_targets)
    scaled_targets = list_targets.copy() - max_target
    sigma_f = 1e-3 + np.std(scaled_targets)**2          #æˆ‘è¦æ”¾ä¸€ä¸ªflagï¼Œè¿™é‡Œkernelæ˜¯å’‹å®šä¹‰çš„ï¼Œä¼šå®æ—¶æ›´æ–°å—ï¼Ÿ

		'''
		max_targetï¼šè®°å½•è®­ç»ƒç›®æ ‡ï¼ˆèƒ½é‡ï¼‰ä¸­çš„æœ€å¤§å€¼ï¼ˆæ ‡é‡ï¼‰ã€‚
		ä¸ºä»€ä¹ˆå‡å»æœ€å¤§å€¼ï¼Ÿ è¿™æ˜¯å¸¸è§çš„æ•°å€¼ç¨³å®šæ€§/ç¼©æ”¾æŠ€å·§ï¼šå°†èƒ½é‡å‘ä¸‹å¹³ç§»ï¼Œä½¿æœ€å¤§å€¼å˜ä¸º 0ã€‚åŸå› åŒ…æ‹¬æé«˜ GP æ•°å€¼ç¨³å®šæ€§ï¼ˆèƒ½é‡èŒƒå›´å‡å°ï¼‰ï¼Œä»¥åŠåé¢åœ¨ç”¨ max_target æ¢å¤ç»å¯¹èƒ½é‡æ—¶æ–¹ä¾¿ã€‚
		scaled_targets = list_targets - max_targetï¼šæŠŠèƒ½é‡å‘ä¸‹å¹³ç§»ã€‚ç»“æœå¤šæ•°ä¸ºè´Ÿæˆ–é›¶ã€‚
		sigma_f = 1e-3 + np.std(scaled_targets)**2ï¼šè®¡ç®—æ ¸çš„è¾“å‡ºå°ºåº¦ï¼ˆsignal varianceï¼‰çš„åˆå€¼ã€‚
		np.std(scaled_targets)**2ï¼š
		A. æ˜¯ scaled_targets çš„æ–¹å·®ï¼ˆå³ä¼°è®¡çš„ä¿¡å·å¼ºåº¦ï¼‰ï¼Œå†åŠ ä¸Š 1e-3 åšä¸‹é™é¿å…ä¸º 0ã€‚
		B. è¿™ä¼šè¢«å½“ä½œ kernel çš„ scalingï¼ˆæŒ¯å¹…ï¼‰åˆå€¼æˆ–å›ºå®šå€¼ã€‚
		æ³¨æ„/å‘ï¼šè‹¥ list_targets çš„ scale å¾ˆå°æˆ–è®­ç»ƒç‚¹æå°‘ï¼Œsigma_f å¯èƒ½å¾ˆå°ï¼Œéœ€è¦æ£€æŸ¥æ•°å€¼èŒƒå›´ã€‚
		'''

    dimension = 'single'               # è¡¨æ˜ kernel åº”ç”¨åœ¨â€œå•ä¸€ç»´åº¦â€çš„æƒ…å½¢ï¼ˆè¿™é‡Œ ML-NEB é‡Œå¸¸ç”¨æ²¿è·¯å¾„çš„å•å˜é‡è·ç¦»ä½œä¸ºå†…æ ¸è¾“å…¥ï¼‰ï¼Œæˆ–è¡¨ç¤ºç‰¹å¾ç©ºé—´çš„å¤„ç†æ–¹å¼ï¼›å…·ä½“è¯­ä¹‰ä¾å®ç°è€Œå®šã€‚
    bounds = ((0.1, path_distance),)   # ç»™æ ¸é•¿åº¦å°ºåº¦ï¼ˆwidthï¼‰çš„å¯é€‰èŒƒå›´è®¾ç½®ä¸‹ç•Œ 0.1ï¼Œä¸Šç•Œ path_distanceã€‚
		'''
		bounds = ((width_min, width_max),) RBF kernel å¯èƒ½æœ‰å¤šä¸ªè¶…å‚æ•°ï¼ˆlengthscaleã€scalingâ€¦ï¼‰ï¼Œ æ¯ä¸ªè¶…å‚æ•°éƒ½æœ‰ä¸€ä¸ª (min, max) è¾¹ç•Œ
		'''



    width = path_distance / 2          # å°† kernel çš„åˆå§‹é•¿åº¦å°ºåº¦è®¾ä¸ºè·¯å¾„è·ç¦»çš„ä¸€åŠï¼ˆç›´è§‚ä¸Šï¼Œè‹¥ path_distance è¡¨ç¤ºæ•´ä½“å°ºåº¦ï¼Œè¿™æ ·é•¿åº¦å°ºåº¦åœ¨åˆç†èŒƒå›´ï¼‰ã€‚

    if np.isnan(width) or width <= 0.05:
        width = path_distance / 2
		'''
		kernel çš„ widthï¼ˆé•¿åº¦å°ºåº¦ï¼‰å†³å®šäº†å‡½æ•°åœ¨è¾“å…¥ç©ºé—´ï¼ˆè¿™é‡Œå¯èƒ½æ˜¯ path coordinateï¼‰ä¸Šç›¸å…³æ€§è¡°å‡é€Ÿåº¦ã€‚
		é€‰æ‹©ä¸ path_distance ç›¸å…³çš„å°ºåº¦ï¼Œæ˜¯ä¸ºäº†è®© kernel åœ¨æ•´æ¡è·¯å¾„å°ºåº¦ä¸Šæœ‰åˆç†çš„å¹³æ»‘æ€§ã€‚
		'''


		# å™ªå£°è¶…å‚æ•°ï¼ˆè§‚æµ‹å™ªå£°ï¼‰
    noise_energy = 0.005
    noise_forces = 0.0005
		# è¿™ä¸¤é¡¹æ˜¯è§‚æµ‹å™ªå£°ï¼ˆlikelihood noiseï¼‰åˆå€¼æˆ–è¶…å‚ï¼šåˆ†åˆ«å¯¹èƒ½é‡å’ŒåŠ›è®¾å®šå™ªå£°æ–¹å·®æˆ–å°ºåº¦ã€‚
		# å«ä¹‰ï¼šGP æ¨¡å‹ä¼šè®¤ä¸ºæµ‹å¾—çš„çœŸå®èƒ½é‡ä¸åŠ›å¸¦æœ‰è¿™äº›æ°´å¹³çš„è§‚æµ‹å™ªå£°ï¼ˆæˆ–ä¸ç¡®å®šæ€§ï¼‰ã€‚è¿™æœ‰åŠ©äºé¿å…è¿‡æ‹Ÿåˆå¹¶æé«˜æ•°å€¼ç¨³å®šæ€§ã€‚
		# æ•°å€¼ä¸Šï¼š0.005 eV èƒ½é‡å™ªå£°ã€0.0005 eV/Ã… åŠ›å™ªå£°ï¼Œè¿™äº›æ˜¯ç»éªŒæ•°å€¼ï¼Œå–å†³äºæ•°æ®æ¥æºï¼ˆDFT çš„æ•°å€¼è¯¯å·®é€šå¸¸ < 1e-3â€“1e-2 eVï¼ŒåŠ›è¯¯å·®äº¦ç±»ä¼¼ï¼‰ã€‚

  	# æ„é€  kernel é…ç½®å­—å…¸
		kdict = [{'type': 'gaussian', 'width': width,
              'dimension': dimension,
              'bounds': bounds,
              'scaling': sigma_f,
              'scaling_bounds': ((sigma_f, sigma_f),)},
             {'type': 'noise_multi',
              'hyperparameters': [noise_energy, noise_forces],
              'bounds': ((0.001, 0.005),
                         (0.0005, 0.002),)}
             ]
			'''
			kdict æ˜¯ä¸€ä¸ª kernel åˆ—è¡¨ï¼ç»„åˆæè¿°ï¼š
			ç¬¬ä¸€é¡¹æ˜¯ gaussianï¼ˆä¹Ÿå°±æ˜¯ RBF / squared-exponentialï¼‰æ ¸ï¼Œ
			        è®¾ç½®äº† widthï¼ˆé•¿åº¦å°ºåº¦ï¼‰ã€dimensionï¼ˆåº”ç”¨ç»´åº¦ï¼‰ã€boundsï¼ˆé•¿åº¦å°ºåº¦å¯ä¼˜åŒ–åŒºé—´ï¼‰ã€scalingï¼ˆè¾“å‡ºæ–¹å·®åˆå€¼ï¼‰å’Œ scaling_bounds
			       ï¼ˆè¿™é‡ŒæŠŠ scaling çš„ä¸Šä¸‹ç•Œéƒ½è®¾ä¸º (sigma_f, sigma_f)ï¼Œè¡¨ç¤ºå›ºå®š scaling ä¸º sigma_fï¼Œä¸è®©å®ƒè¢«ä¼˜åŒ–ï¼‰ã€‚
			ç¬¬äºŒé¡¹ 'noise_multi' æ˜¯è§‚æµ‹å™ªå£°æ ¸ï¼ŒåŒ…å«èƒ½é‡å’ŒåŠ›çš„å™ªå£°è¶…å‚æ•°åŠå…¶å…è®¸èŒƒå›´ï¼ˆboundsï¼‰ã€‚
			æ•ˆæœï¼šGP kernel = GaussianKernel * scaling + noise_multiï¼› 
			      noise_multi è¡¨ç¤ºè§‚æµ‹æ–¹å·®ï¼ˆèƒ½é‡ä¸åŠ›åˆ†åˆ«ï¼‰ã€‚æŠŠ scaling_bounds å›ºå®šä¸º (sigma_f, sigma_f) æ„å‘³ç€ä¸å…è®¸ GP å»ä¼˜åŒ–è¾“å‡ºæŒ¯å¹…ï¼ˆå¯èƒ½æ˜¯ä½œè€…çš„ä¸€ç§ç¨³å®šåŒ–åšæ³•ï¼‰ã€‚
			æ³¨æ„ï¼šå›ºå®š scaling å¯ç¨³å®šè®­ç»ƒä½†ä¼šé™åˆ¶æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ï¼›å¯ä»¥é€šè¿‡æŠŠ scaling_bounds æ”¹æˆèŒƒå›´æ¥å…è®¸ä¼˜åŒ–ã€‚
			'''



    # å¤åˆ¶è®­ç»ƒæ•°æ®ä¸æ ¹æ®æ©ç å±è”½
    train = list_train.copy()
    gradients = list_gradients.copy()
    if index_mask is not None:
        train = apply_mask(list_to_mask=list_train,
                           mask_index=index_mask)[1]
        gradients = apply_mask(list_to_mask=list_gradients,
                               mask_index=index_mask)[1]
    parprint('\n')
    parprint('Training a Gaussian process...')
    parprint('Number of training points:', len(scaled_targets))


		# æ„å»º GaussianProcess å¯¹è±¡
    gp = GaussianProcess(kernel_list=kdict,
                         regularization=0.0,
                         regularization_bounds=(0.0, 0.0),
                         train_fp=train,
                         train_target=scaled_targets,
                         gradients=gradients,
                         optimize_hyperparameters=False,
                         scale_data=False)
		'''
		è¿™é‡Œåˆ›å»ºäº† GaussianProcess å®ä¾‹ï¼ˆæ¥è‡ª CatLearn/ç›¸å…³åº“ï¼‰ï¼Œä¼ å…¥å‚æ•°è¯´æ˜ï¼š
		kernel_list=kdictï¼šä½¿ç”¨ä¸Šé¢é…ç½®çš„æ ¸ç»„åˆã€‚
		regularization=0.0ï¼šä¸æ·»åŠ é¢å¤–çš„æ­£åˆ™é¡¹ï¼ˆå¯èƒ½å½±å“æ ¸çŸ©é˜µçš„ç¨³å®šæ€§ï¼‰ã€‚
		train_fp=trainï¼šè®­ç»ƒç‰¹å¾ï¼ˆfingerprintsï¼‰ã€‚
		train_target=scaled_targetsï¼šè®­ç»ƒç›®æ ‡ï¼ˆå·²ç¼©æ”¾çš„èƒ½é‡ï¼‰ã€‚
		gradients=gradientsï¼šè®­ç»ƒæ—¶åŒæ—¶ä¼ å…¥æ¢¯åº¦ä¿¡æ¯ï¼ˆforcesï¼‰ï¼ŒGP å°†ä»¥â€œjointâ€æ–¹å¼å­¦ä¹ èƒ½é‡ä¸æ¢¯åº¦ï¼ˆå¤šé¡¹å¼æ ¸æˆ– gradient-enabled GPï¼‰ã€‚
		optimize_hyperparameters=Falseï¼šåœ¨æ„é€ æ—¶ä¸è‡ªåŠ¨ä¼˜åŒ–è¶…å‚æ•°ï¼ˆä½†ä¸‹é¢ä¼šæ‰‹åŠ¨è°ƒç”¨ä¼˜åŒ–ï¼‰ã€‚
		scale_data=Falseï¼šä¸å¯¹è¾“å…¥æ•°æ®åšé¢å¤–ç¼©æ”¾ï¼ˆå› ä¸ºä½œè€…è‡ªå·±å·²åšäº† scaled_targetsï¼‰ã€‚
		æ³¨æ„ï¼šgradients çš„ä¼ å…¥å¯¹äº GP æ¥è¯´å¾ˆå…³é”®â€”â€”ä½¿ç”¨åŠ›ä¿¡æ¯èƒ½æ˜¾è‘—æé«˜æ¨¡å‹å¯¹åŠ¿èƒ½é¢çš„å­¦ä¹ æ•ˆç‡ï¼Œä½†è¦æ±‚ kernel æ”¯æŒ force observationsï¼Œå¹¶ä¸” train_fp ä¸ gradients çš„å¯¹é½å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼ˆæ¯ä¸ªè®­ç»ƒç‚¹çš„ feature å¯¹åº”å…¶æ¢¯åº¦ï¼‰
		'''

    gp.optimize_hyperparameters(global_opt=False)
    if fullout:
        parprint('Optimized hyperparameters:', gp.kernel_list)
    parprint('Gaussian process trained.')

    return gp, max_target
		# è¿”å›è®­ç»ƒå¥½çš„ gpï¼ˆä¸€ä¸ªå¯ç”¨äºé¢„æµ‹èƒ½é‡/åŠ›/ä¸ç¡®å®šåº¦çš„æ¨¡å‹ï¼‰ä»¥åŠ max_targetï¼ˆç”¨äºæŠŠ GP é¢„æµ‹çš„ scaled èƒ½é‡è¿˜åŸä¸ºçœŸå®å°ºåº¦ï¼šE_real = E_pred + max_targetï¼‰


# ======================================
# å…ˆç”¨ GP é¢„æµ‹çš„ NEB è·¯å¾„ä¸Šæ”¶é›†ç»“æœ
# å‡½æ•°ç›®çš„ï¼šåœ¨â€œé¢„æµ‹çš„åŠ¿èƒ½é¢â€ï¼ˆå³ images æŒ‚äº† ASECalcã€ç”¨ GP é¢„æµ‹ï¼‰ä¸Šï¼Œè®¡ç®—è·¯å¾„çš„â€œæ‹Ÿåˆæ›²çº¿â€ï¼ˆs,e,sfit,efitï¼‰ï¼Œ
# å¹¶å¯¹æ¯ä¸ª image å¾—åˆ° GP çš„ä¸ç¡®å®šåº¦å’Œè¯¥ image çš„ï¼ˆé¢„æµ‹ï¼‰èƒ½é‡ï¼Œä¿å­˜åˆ°å¯¹è±¡é‡Œä»¥ä¾›åç»­å†³ç­–ï¼ˆacquisitionï¼‰ä½¿ç”¨
def get_results_predicted_path(self):

    """
    Obtain results from the predicted NEB.
    """

    neb_tools = NEBTools(self.images)   # NEBToolsï¼ˆæ¥è‡ª ASE çš„ neb utilitiesï¼‰ç”¨æ¥å¯¹ç¦»æ•£ images åšè·¯å¾„æ‹Ÿåˆå’Œå¹³æ»‘å¤„ç†ã€‚self.images æ˜¯ä¸€ä¸ª list of ase.Atomsï¼ˆé•¿åº¦ n_imagesï¼‰
    [self.s, self.e, self.sfit, self.efit] = neb_tools.get_fit()[0:4]
		'''
		neb_tools.get_fit() è¿”å›ä¸€ç»„æ‹Ÿåˆç»“æœï¼Œå¸¸è§å‰å››é¡¹ï¼š
		sï¼šè·¯å¾„åæ ‡ï¼ˆç´¯ç§¯å¼§é•¿ï¼‰æ•°ç»„ï¼ˆé•¿åº¦ = n_imagesï¼‰
		eï¼šåŸå§‹èƒ½é‡æ•°ç»„ï¼ˆå¯¹åº”æ¯ä¸ª image çš„èƒ½é‡ï¼‰
		sfitï¼šç”¨äºç»˜å›¾/å†…æ’çš„æ‹Ÿåˆè·¯å¾„åæ ‡
		efitï¼šæ‹Ÿåˆå¾—åˆ°çš„èƒ½é‡ï¼ˆå¯¹åº” sfitï¼‰
		è¿™é‡ŒæŠŠå‰ 4 ä¸ªç»“æœè§£åŒ…åˆ° self.s, self.e, self.sfit, self.efit
		'''
    self.path_distance = self.s[-1]  # path_distance = è·¯å¾„æ€»é•¿åº¦ï¼ˆå¼§é•¿ï¼‰ï¼Œå­˜ä¸ºæ ‡é‡ï¼Œåç»­è¢«å½“ä½œå°ºåº¦å‚æ•°ä½¿ç”¨
    # åˆå§‹åŒ–ä¸¤ä¸ªåˆ—è¡¨ç”¨äºå­˜ä¸ç¡®å®šåº¦å’Œèƒ½é‡ï¼Œç„¶åéå†æ¯ä¸€å¸§ iï¼ˆå•ä¸ª ase.Atomsï¼‰ã€‚
		self.uncertainty_path = []
    self.e_path = []
    for i in self.images:
        pos_unc = [i.get_positions().flatten()]                 # å–å¾—è¯¥ image çš„åæ ‡æ•°ç»„ï¼ˆ(N_atoms,3)ï¼‰ï¼Œflatten() æˆä¸€ç»´é•¿åº¦ 3*N_atomsã€‚ç„¶åç”¨æ–¹æ‹¬å·åŒ…æˆä¸€ä¸ªåŒ…å«å•ä¸ªæ ·æœ¬çš„ listï¼ˆå½¢å¦‚ [array([..., ...])]ï¼‰ï¼Œä»¥ç¬¦åˆ apply_mask / gp.predict æœŸæœ›çš„æ‰¹æ¬¡è¾“å…¥æ ¼å¼ï¼ˆé€šå¸¸æ˜¯ list-of-vectors æˆ– 2D arrayï¼‰ã€‚
        pos_unc = apply_mask(list_to_mask=pos_unc,
                             mask_index=self.index_mask)[1]     # apply_mask(...) æŠŠå…¨å±€åæ ‡å‘é‡ææ‰è¢«çº¦æŸçš„è‡ªç”±åº¦ï¼ˆindex_mask é€šå¸¸æ˜¯è¢«å›ºå®šåŸå­å¯¹åº”çš„ç´¢å¼•ï¼‰ï¼Œè¿”å›å¤šä¸ªå€¼ï¼å…ƒç»„ï¼Œ[1] å–æ©ç åç”¨äºè®­ç»ƒ/é¢„æµ‹çš„å‘é‡åˆ—è¡¨ï¼ˆæ³¨æ„è¿”å›æ ¼å¼è¦ä¸ä½ çš„å®ç°å¯¹åº”ï¼‰ã€‚ç»“æœ pos_unc ä»æ˜¯å¯è¢« gp.predict(test_fp=...) æ¥å—çš„å½¢çŠ¶
        u = self.gp.predict(test_fp=pos_unc, uncertainty=True)  # ç”¨ GP å¯¹è¿™ä¸ªimageé¢„æµ‹ï¼Œå¹¶è¯·æ±‚ä¸ç¡®å®šåº¦ï¼ˆuncertainty=Trueï¼‰ã€‚GP è¿”å› uï¼Œæ˜¯ dictï¼ˆå®ç°ä¾èµ–ï¼‰ï¼Œè¿™é‡Œå– u['uncertainty_with_reg']ï¼ˆå¸¦æ­£åˆ™åŒ–çš„ sigmaï¼‰ï¼Œå–ç¬¬ 0 ä¸ªæ ·æœ¬å¹¶ä¹˜ä»¥ 2.0ï¼ˆé€šå¸¸æŠŠ 1Ïƒ æ‰©å±•ä¸º 2Ïƒï¼Œç”¨ä½œä¿å®ˆçš„ä¸ç¡®å®šåº¦ä¼°è®¡ï¼›ä¹Ÿå¯èƒ½ç”¨äº 95% åŒºé—´çš„è¿‘ä¼¼ï¼‰ï¼Œå¾—åˆ° uncertainty æ ‡é‡ã€‚
        uncertainty = 2.0 * u['uncertainty_with_reg'][0]
        i.info['uncertainty'] = uncertainty                     # æŠŠ uncertainty å†™åˆ°è¯¥ image çš„ info å­—å…¸ï¼Œä¾›åç»­å­˜æ–‡ä»¶æˆ–è°ƒè¯•ã€‚
        self.uncertainty_path.append(uncertainty)               # åŒæ—¶æŠŠ uncertainty åŠ å…¥ self.uncertainty_path åˆ—è¡¨ã€‚
        self.e_path.append(i.get_total_energy())                # i.get_total_energy()ï¼šè§¦å‘è¯¥ image çš„ calculatorï¼ˆå¦‚æœæ˜¯ä¸­é—´ imageï¼Œé€šå¸¸ä¸º ASECalcï¼‰ çš„ calculateï¼Œä»è€Œè¿”å› GP é¢„æµ‹çš„èƒ½é‡ï¼ˆæˆ–è€…ç«¯ç‚¹çš„çœŸå®èƒ½é‡ï¼‰ã€‚æŠŠå®ƒè¿½åŠ åˆ° self.e_pathã€‚
    self.images[0].info['uncertainty'] = 0.0
    self.images[-1].info['uncertainty'] = 0.0
		# æ€»ç»“ get_results_predicted_pathï¼š 
		# å–å¾— NEB æ‹Ÿåˆç»“æœï¼Œè®¡ç®—å¹¶æ”¶é›†è·¯å¾„ä¸Šæ¯å¼  image çš„ GP ä¸ç¡®å®šåº¦ä¸ï¼ˆé¢„æµ‹ï¼‰èƒ½é‡ï¼Œä¿å­˜åˆ° self.uncertainty_path ä¸ self.e_pathï¼ˆåè€…ç”¨äº acqã€åˆ¤æ–­èƒ½é‡é«˜ç‚¹ç­‰ï¼‰ã€‚

# =======================================

class ASECalc(Calculator):
# ç”¨ GP é¢„æµ‹èƒ½é‡å¹¶ç”¨æœ‰é™å·®åˆ†ä¼°ç®—åŠ›
    """
    CatLearn/ASE calculator.
		æ•´ä½“ç›®çš„ï¼šå®ç°ä¸€ä¸ªç¬¦åˆ ASE Calculator æ¥å£çš„è®¡ç®—å™¨ï¼Œ
		ä½¿å¾—å½“åœ¨ä¸­é—´ images ä¸Šè°ƒç”¨ get_potential_energy() / get_forces() æ—¶ï¼Œ
		èƒ½ç”¨ GP ç»™å‡ºèƒ½é‡å¹¶ç”¨æœ‰é™å·®åˆ†è®¡ç®—åŠ›ï¼ˆè€Œä¸æ˜¯è°ƒç”¨ DFTï¼‰ã€‚è¿™å…è®¸åœ¨â€œé¢„æµ‹åŠ¿èƒ½é¢â€ä¸Šè¿è¡Œ NEB
    """

    implemented_properties = ['energy', 'forces']
    nolabel = True

    def __init__(self, gp, index_constraints, scaling_targets,
                 finite_step=1e-4, **kwargs):

        Calculator.__init__(self, **kwargs)

        self.gp = gp                              # ä¼ å…¥çš„ GP æ¨¡å‹ï¼ˆå¯é¢„æµ‹èƒ½é‡ predictï¼‰
        self.scaling = scaling_targets						# ç¼©æ”¾/å¹³ç§»å€¼ï¼ˆç”¨äºæŠŠ GP çš„ scaled è¾“å‡ºæ¢å¤åˆ°çœŸå®èƒ½é‡ï¼‰
        self.fs = finite_step
        self.ind_constraints = index_constraints  # è¢«æ©ç çš„ç´¢å¼•ï¼ˆå“ªäº›è‡ªç”±åº¦å‚ä¸ finite-differenceï¼‰
		
		# ---
		# ASE çš„æ ‡å‡†æ¥å£ï¼Œå†…éƒ¨æŠŠèƒ½é‡ä¸åŠ›å†™å…¥ self.results.
    def calculate(self, atoms=None, properties=['energy', 'forces'],
                  system_changes=all_changes):

        # Atoms object.
        self.atoms = atoms

        def pred_energy_test(test, gp=self.gp, scaling=self.scaling):

            # Get predictions.
						# è°ƒç”¨ GP çš„ predictï¼ˆä¸è¯·æ±‚ä¸ç¡®å®šåº¦ï¼‰ï¼Œ
						# GP è¿”å› predictions['prediction']ï¼ˆå¯èƒ½æ˜¯å½¢å¦‚ [[E_pred]]ï¼‰ï¼Œå–ç¬¬ 0 ä¸ªæ ·æœ¬å’Œç¬¬ 0 ä¸ªè¾“å‡ºï¼Œå†åŠ ä¸Š scalingï¼ˆç¼©æ”¾å‚æ•°ï¼‰ã€‚
						# è¿™é‡Œçš„ scaling å¯¹åº”å‰é¢ max_target çš„æ¢å¤ï¼šè®­ç»ƒæ—¶æŠŠ target å‡å»äº† max_targetï¼Œé¢„æµ‹åè¦åŠ å›å»ã€‚
            predictions = gp.predict(test_fp=test, uncertainty=False)
            return predictions['prediction'][0][0] + scaling

        Calculator.calculate(self, atoms, properties, system_changes)

        pos_flatten = self.atoms.get_positions().flatten()               # å½“å‰ Atoms çš„å…¨å±€åæ ‡å±•å¹³ï¼ˆå½¢çŠ¶ (3*N_atoms,)ï¼‰

        test_point = apply_mask(list_to_mask=[pos_flatten],              # å¯¹å…¶åº”ç”¨æ©ç ï¼Œåªä¿ç•™è‡ªç”±åº¦ï¼ˆä¾‹å¦‚å¦‚æœæŸäº›åŸå­å›ºå®šï¼Œåˆ™å»æ‰å¯¹åº”åˆ†é‡ï¼‰ï¼Œç»“æœæ˜¯ [vector]ï¼ˆlistï¼Œå•æ ·æœ¬ï¼‰ã€‚
                                mask_index=self.ind_constraints)[1]

        # Get energy.
        energy = pred_energy_test(test=test_point)

        # Get forces:
				# é¢„æµ‹åŠ›ï¼ˆæœ‰é™å·®åˆ†ï¼‰: ä»£ç é€šè¿‡å¯¹æ¯ä¸ªè¢«æ©ç çš„è‡ªç”±åº¦ä½œæ­£/è´Ÿå¾®å°æ‰°åŠ¨ï¼Œä½¿ç”¨ GP é¢„æµ‹æ‰°åŠ¨åçš„èƒ½é‡ï¼Œç„¶åä»¥ä¸­å¿ƒå·®åˆ†è®¡ç®—è¯¥è‡ªç”±åº¦å¯¹åº”çš„èƒ½é‡å¯¼æ•°ï¼ˆdE/dqï¼‰ï¼Œè¿›è€Œå¾—åˆ°åŠ›ã€‚
        

				# åˆ†åˆ«æ”¶é›†å¯¹æ¯ä¸ªè¢«æ©ç è‡ªç”±åº¦æ­£/è´Ÿæ‰°åŠ¨åçš„ç‰¹å¾å‘é‡ï¼ˆæ¯è¡Œä¸€ä¸ªæ‰°åŠ¨æ ·æœ¬ï¼‰ã€‚
				geom_test_pos = np.zeros((len(self.ind_constraints),
                                  len(test_point[0])))
        geom_test_neg = np.zeros((len(self.ind_constraints),
                                  len(test_point[0])))

        for i in range(len(self.ind_constraints)): # å¾ªç¯ï¼šå¯¹æ¯ä¸ªæ©ç ç´¢å¼• index_forceï¼Œæ„é€  posï¼ˆä» test_point å‡ºå‘ï¼‰å¹¶åœ¨è¯¥æ©ç åæ ‡ä½ç½®åŠ /å‡ self.fsï¼ˆå¾®å°æ­¥é•¿ï¼‰ã€‚
            index_force = self.ind_constraints[i]
            pos = test_point.copy()[0]

            pos[i] = pos_flatten[index_force] + self.fs
            geom_test_pos[i] = pos

            pos[i] = pos_flatten[index_force] - self.fs
            geom_test_neg[i] = pos

        f_pos = self.gp.predict(test_fp=geom_test_pos)['prediction'] # å¯¹è¿™äº›æ‰°åŠ¨æ ·æœ¬æ‰¹é‡é¢„æµ‹èƒ½é‡
        f_neg = self.gp.predict(test_fp=geom_test_neg)['prediction'] # å¯¹è¿™äº›æ‰°åŠ¨æ ·æœ¬æ‰¹é‡é¢„æµ‹èƒ½é‡

        gradients_list = (-f_neg + f_pos) / (2.0 * self.fs)  # ç®—å‡º dE/dq çš„æœ‰é™å·®åˆ†
        gradients = np.zeros(len(pos_flatten))
        for i in range(len(self.ind_constraints)):
            index_force = self.ind_constraints[i]
            gradients[index_force] = gradients_list[i]
        # forï¼šè¿™äº›æ¢¯åº¦å†™å›åˆ° gradients å‘é‡çš„å¯¹åº”å…¨å±€ä½ç½® index_force

        forces = np.reshape(-gradients, (self.atoms.get_number_of_atoms(), 3))  # å› ä¸ºåŠ› F = -âˆ‡Eï¼Œæ‰€ä»¥å¯¹èƒ½é‡æ¢¯åº¦å–è´Ÿå·å¾—åˆ°åŠ›ï¼Œreshape æˆæ¯åŸå­ 3 åˆ†é‡çš„æ•°ç»„ï¼Œå¹¶å†™å…¥ self.results.

        # Results:
        self.results['energy'] = energy
        self.results['forces'] = forces

# =======================================
# ä»æ¢¯åº¦å¾—åˆ°æ¯ç»“æ„çš„ fmax
def get_fmax(gradients_flatten):

    """
    Function that print a list of max. individual atom forces.
    å‡½æ•°ç›®çš„ï¼šæŠŠä¸€æ‰¹æ¢¯åº¦ï¼ˆæ¯ä¸ªæ¢¯åº¦æ˜¯æ‰å¹³åŒ–çš„ 3N å‘é‡ï¼‰å˜æˆâ€œæ¯ä¸ªç»“æ„çš„æœ€å¤§å•åŸå­åŠ›èŒƒæ•°â€
		"""

    forces_flatten = -gradients_flatten # ç»Ÿä¸€æŠŠ gradientsï¼ˆè¿™é‡Œæ¢¯åº¦è¢«å®šä¹‰ä¸º âˆ‚E/âˆ‚xï¼‰å–è´Ÿå¾—åˆ°ç‰©ç†åŠ› Fï¼ˆå› ä¸º F = -âˆ‡Eï¼‰
    
		'''
		å¾ªç¯æ¯ä¸ªæ ·æœ¬ iï¼ˆä¸€è¡Œæ‰å¹³å‘é‡ï¼‰ï¼Œreshape æˆ (N_atoms,3)ï¼Œè®¡ç®—æ¯ä¸ªåŸå­çš„åŠ›å¤§å° sqrt(fx^2+fy^2+fz^2)ï¼Œç„¶åå–æœ€å¤§å€¼ï¼ˆå³è¯¥ç»“æ„çš„ fmaxï¼‰ï¼Œå†™å…¥ list_fmaxã€‚
		è¿”å›å½¢çŠ¶ (M,1) çš„æ•°ç»„ï¼ŒM ä¸ºæ ·æœ¬æ•°
		'''
		list_fmax = np.zeros((len(gradients_flatten), 1))
    j = 0
    for i in forces_flatten:
        atoms_forces_i = np.reshape(i, (-1, 3))
        list_fmax[j] = np.max(np.sqrt(np.sum(atoms_forces_i**2, axis=1)))
        j = j + 1
    return list_fmax # å°æé†’ï¼šè¿™æ­£æ˜¯ ASE ä¸­å¸¸ç”¨çš„æ”¶æ•›åˆ¤æ® â€”â€” æœ€å¤§åŸå­åŠ›æ¨¡ï¼ˆè€Œä¸æ˜¯æŸä¸ªåŠ›åˆ†é‡æˆ–å…¨å±€èŒƒæ•°ï¼‰ã€‚

# =======================================
def get_energy_catlearn(self, x=None): # ç”¨çœŸå® ASE è®¡ç®—å™¨è¯„ä¼°çœŸå€¼
'''
get_energy_catlearn(self, x=None) å’Œ get_forces_catlearn(self, x=None) â€” ç”¨çœŸå® ASE è®¡ç®—å™¨è¯„ä¼°çœŸå€¼
è¿™ä¸¤ä¸ªå‡½æ•°ç”¨äºåœ¨éœ€è¦æ—¶è°ƒç”¨çœŸå®çš„ ASE calculatorï¼ˆæ¯”å¦‚ VASP/GPAWï¼‰ å¯¹æŒ‡å®šç‚¹åšä¸€æ¬¡çœŸå®è¯„ä¼°ï¼ˆèƒ½é‡ä¸åŠ›ï¼‰ï¼Œå¹¶æŠŠç»“æœè¿”å›ï¼Œç”¨äºæŠŠçœŸå®æ•°æ®åŠ å…¥è®­ç»ƒé›†ã€‚
'''

    """ Evaluates the objective function at a given point in space.

    Parameters
    ----------
    self: arrays
        Previous information from the CatLearn optimizer.
    x : array
        Array containing the atomic positions (flatten).

    Returns
    -------
    energy : float
        The function evaluation value.
    """
    energy = 0.0

    # If no point is passed, evaluate the last trained point.
    if x is None:
        x = self.list_train[-1]

    # Get energies using ASE:
    pos_ase = array_to_ase(x, self.num_atoms) # æŠŠæ‰å¹³åŒ–ä¸€ç»´åæ ‡è½¬ä¸º ASE positionsï¼Œå¹¶è¿”å› pos_aseï¼ˆå½¢çŠ¶ (N_atoms,3)ï¼‰æˆ– Atoms å¯¹è±¡ã€‚

    self.ase_ini.set_calculator(None)
    self.ase_ini = Atoms(self.ase_ini, positions=pos_ase,
                         calculator=self.ase_calc)
		# self.ase_ini : ä¸€ä¸ª ase.Atoms æ¨¡æ¿ï¼ˆå«åŸå­ç±»å‹/åŸºå…ƒï¼‰ï¼Œ
		# è¯¥å¥æŠŠæ–°ä½ç½®å’Œ çœŸå®è®¡ç®—å™¨ self.ase_calc ç»‘å®šåˆ°å®ƒä¸Šé¢ï¼ˆæ³¨æ„è¿™é‡Œ self.ase_calc æ˜¯å¯¹è±¡é‡Œäº‹å…ˆè®¾ç½®çš„çœŸå® ASE calculatorï¼Œæ¯”å¦‚ VASP/GPAWï¼‰ã€‚
		# è¿™æ ·ä¿è¯æ¥ä¸‹æ¥å¯¹ self.ase_ini.get_potential_energy(...) çš„è°ƒç”¨ä¼šè§¦å‘çœŸå® DFT è®¡ç®—ï¼Œè€Œä¸æ˜¯ GPã€‚
    energy = self.ase_ini.get_potential_energy(force_consistent=self.fc) # è°ƒç”¨çœŸå® calculator çš„ get_potential_energy()ï¼Œå¾—åˆ°çœŸèƒ½é‡å¹¶è¿”å›ï¼ˆforce_consistent å½±å“æ˜¯å¦è¿”å›å’ŒåŠ›ä¸€è‡´çš„ 0 K èƒ½é‡ï¼›ç»†èŠ‚å–å†³ calculatorï¼‰
    return energy

# =======================================
def get_forces_catlearn(self, x=None):

    """ Evaluates the forces (ASE) or the Jacobian of the objective
    function at a given point in space.

    Parameters
    ----------
    self: arrays
        Previous information from the CatLearn optimizer.
    x : array
        Atoms positions or point in space.

    Returns
    -------
    forces : array
        Forces of the atomic structure (flatten).
    """
    forces = 0.0
    # If no point is passed, evaluate the last trained point.
    if x is None:
        x = self.list_train[-1]

    # Get energies using ASE:
    forces = self.ase_ini.get_forces().flatten()
    return forces

# =======================================
def eval_and_append(self, interesting_point):
# æŠŠè¢«é‡‡æ ·ç‚¹è¯„ä¼°å¹¶è¿½åŠ åˆ°è®­ç»ƒé›†ä¸­
# å‡½æ•°ç›®çš„ï¼šå¯¹ acquisition é€‰ä¸­çš„ interesting_point åšçœŸå®è®¡ç®—ï¼ˆèƒ½é‡+åŠ›ï¼‰ï¼Œ
# å¹¶æŠŠæ•°æ®è¿½åŠ åˆ° self.list_train, self.list_targets, self.list_gradientsï¼Œ
# å¹¶æ›´æ–°è®¡æ•°å™¨ self.fevalã€‚
    """ Evaluates the energy and forces (ASE) of the point of interest
        for a given atomistic structure.

    Parameters
    ----------
    self: arrays
        Previous information from the CatLearn optimizer.
    interesting_point : ndarray
        Atoms positions or point in space.

    Return
    -------
    Append function evaluation and forces values to the training set.
    """

    if np.ndim(interesting_point) == 1: # ç¡®ä¿ interesting_point æ˜¯æ‰¹é‡æ ¼å¼ [vector]ï¼ˆ2Dï¼‰ï¼›ä¾¿äºåç»­ np.append(..., axis=0)
        interesting_point = np.array([interesting_point])

    self.list_train = np.append(self.list_train, # æŠŠæ–°çš„åæ ‡è¡Œè¿½åŠ åˆ° self.list_trainï¼ˆå‡è®¾ list_train æ˜¯ numpy.array çš„äºŒç»´æ•°ç»„ï¼Œå½¢çŠ¶ (M, D)ï¼Œinteresting_point çš„å½¢çŠ¶ (1, D)ï¼Œæ‰€ä»¥ axis=0 è¿½åŠ æ˜¯æ­£ç¡®çš„ï¼‰ã€‚æ³¨æ„ï¼šnp.append å¯¹åˆ—è¡¨/æ•°ç»„æ‹¼æ¥è¦ä¿è¯å½¢çŠ¶ä¸€è‡´ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚
                                interesting_point, axis=0)
    
    # Remove old calculation information 
    self.ase_calc.results = {} # æ¸…ç©º self.ase_calc.resultsï¼ˆæŠŠå…ˆå‰ calculator ç¼“å­˜åˆ æ‰ï¼‰ï¼Œç¡®ä¿ä¸‹ä¸€æ¬¡ get_potential_energy() çœŸæ­£å‘èµ·æ–°çš„è¯„ä¼°è€Œä¸æ˜¯é‡ç”¨ç¼“å­˜ï¼ˆASE Calculator å¯èƒ½æŠŠä¸Šä¸€æ¬¡çš„ç»“æœç¼“å­˜åˆ° .resultsï¼‰ã€‚
    
    energy = get_energy_catlearn(self)

    self.list_targets = np.append(self.list_targets, energy) # è°ƒç”¨ä¸Šæ–‡çš„çœŸå® DFT è¯„ä¼°ï¼Œå¾—åˆ° energyï¼Œè¿½åŠ åˆ° list_targetsã€‚æ³¨æ„è¿™é‡Œ list_targets å¯èƒ½æ˜¯ä¸€ç»´æ•°ç»„ï¼ˆç¨åä¼š reshape æˆ (M,1)ï¼‰ã€‚

    gradients = [-get_forces_catlearn(self).flatten()]
    self.list_gradients = np.append(self.list_gradients,
                                    gradients, axis=0)
		'''
			get_forces_catlearn(self) è¿”å›çœŸå®åŠ› forces.flatten()ï¼ˆè¿™æ˜¯ Fï¼‰ã€‚æ³¨æ„ä»–ä»¬åœ¨å–æ¢¯åº¦æ—¶åŠ äº†è´Ÿå·ï¼šgradients = [-forces]ã€‚ä¸ºä»€ä¹ˆï¼Ÿ
			GP åœ¨è®­ç»ƒä¸­é€šå¸¸æŠŠâ€œæ¢¯åº¦æ ‡ç­¾â€å®šä¹‰ä¸º âˆ‚E/âˆ‚xï¼ˆå³æ­£çš„èƒ½é‡å¯¼æ•°ï¼‰ï¼Œè€Œ ASE è¿”å›çš„æ˜¯ F = -âˆ‚E/âˆ‚xã€‚å› æ­¤ gradients åº”è¯¥æ˜¯ -F æ‰ç­‰äº âˆ‚E/âˆ‚xã€‚
			è¿™é‡Œ get_forces_catlearn è¿”å› forcesï¼Œæ‰€ä»¥ -forces å°±æ˜¯ gradientsï¼ˆå³ âˆ‚E/âˆ‚xï¼‰ï¼Œä»–ä»¬æŠŠå®ƒç”¨ä½œ GP çš„æ¢¯åº¦æ ‡ç­¾ã€‚
			ç„¶åæŠŠè¯¥æ¢¯åº¦ï¼ˆä½œä¸ºä¸€è¡Œï¼‰è¿½åŠ åˆ° self.list_gradientsã€‚
		'''

    self.list_targets = np.reshape(self.list_targets,
                                   (len(self.list_targets), 1)) # list_targets è½¬ä¸ºåˆ—å‘é‡å½¢çŠ¶ (M,1)ï¼ˆGP æ¥å£å¯èƒ½æœŸæœ›è¿™ä¸€å½¢çŠ¶ï¼‰
			

    self.feval += 1 # è‡ªå¢ fevalï¼ˆçœŸå®è¯„ä¼°è®¡æ•°ï¼‰
